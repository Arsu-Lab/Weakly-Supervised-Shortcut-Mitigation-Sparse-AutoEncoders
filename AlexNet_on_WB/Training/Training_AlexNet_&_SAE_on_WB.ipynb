{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d53498c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training AlexNet full-model on WaterBirds dataset:.......................\n",
      "Size of WB_train_loader :  4864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ahsan/.conda/envs/xAI-bio/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50] Train Loss: 0.3802, Val Loss: 0.6631, Train Acc: 0.8922, Val Acc: 0.7725\n",
      "Best model saved at epoch 1 with Val Acc: 0.7725\n",
      "Epoch [2/50] Train Loss: 0.1978, Val Loss: 0.8478, Train Acc: 0.9297, Val Acc: 0.6862\n",
      "Epoch [3/50] Train Loss: 0.1782, Val Loss: 0.6739, Train Acc: 0.9391, Val Acc: 0.7234\n",
      "Epoch [4/50] Train Loss: 0.1760, Val Loss: 0.6856, Train Acc: 0.9391, Val Acc: 0.6862\n",
      "Epoch [5/50] Train Loss: 0.1614, Val Loss: 0.6523, Train Acc: 0.9431, Val Acc: 0.7198\n",
      "Epoch [6/50] Train Loss: 0.1659, Val Loss: 0.6383, Train Acc: 0.9387, Val Acc: 0.7437\n",
      "Epoch [7/50] Train Loss: 0.1566, Val Loss: 0.6795, Train Acc: 0.9416, Val Acc: 0.7090\n",
      "Epoch [8/50] Train Loss: 0.1538, Val Loss: 0.7082, Train Acc: 0.9437, Val Acc: 0.7210\n",
      "Epoch [9/50] Train Loss: 0.1577, Val Loss: 0.7755, Train Acc: 0.9426, Val Acc: 0.6838\n",
      "Epoch [10/50] Train Loss: 0.1495, Val Loss: 0.5547, Train Acc: 0.9481, Val Acc: 0.7365\n",
      "Epoch [11/50] Train Loss: 0.1511, Val Loss: 0.7437, Train Acc: 0.9477, Val Acc: 0.7162\n",
      "Epoch [12/50] Train Loss: 0.1445, Val Loss: 0.9459, Train Acc: 0.9506, Val Acc: 0.6599\n",
      "Epoch [13/50] Train Loss: 0.1407, Val Loss: 0.9109, Train Acc: 0.9510, Val Acc: 0.6838\n",
      "Epoch [14/50] Train Loss: 0.1352, Val Loss: 1.1391, Train Acc: 0.9510, Val Acc: 0.6778\n",
      "Epoch [15/50] Train Loss: 0.1465, Val Loss: 0.7689, Train Acc: 0.9477, Val Acc: 0.7186\n",
      "Epoch [16/50] Train Loss: 0.1407, Val Loss: 0.9619, Train Acc: 0.9479, Val Acc: 0.6994\n",
      "Epoch [17/50] Train Loss: 0.1051, Val Loss: 0.8143, Train Acc: 0.9600, Val Acc: 0.7198\n",
      "Epoch [18/50] Train Loss: 0.0879, Val Loss: 0.8016, Train Acc: 0.9714, Val Acc: 0.7365\n",
      "Epoch [19/50] Train Loss: 0.0772, Val Loss: 0.8974, Train Acc: 0.9743, Val Acc: 0.7222\n",
      "Epoch [20/50] Train Loss: 0.0695, Val Loss: 0.9663, Train Acc: 0.9714, Val Acc: 0.7090\n",
      "Epoch [21/50] Train Loss: 0.0703, Val Loss: 0.8538, Train Acc: 0.9721, Val Acc: 0.7246\n",
      "Epoch [22/50] Train Loss: 0.0631, Val Loss: 0.9952, Train Acc: 0.9777, Val Acc: 0.7102\n",
      "Epoch [23/50] Train Loss: 0.0552, Val Loss: 0.9136, Train Acc: 0.9794, Val Acc: 0.7293\n",
      "Epoch [24/50] Train Loss: 0.0539, Val Loss: 0.9356, Train Acc: 0.9812, Val Acc: 0.7234\n",
      "Epoch [25/50] Train Loss: 0.0524, Val Loss: 0.9246, Train Acc: 0.9823, Val Acc: 0.7257\n",
      "Epoch [26/50] Train Loss: 0.0461, Val Loss: 0.9480, Train Acc: 0.9837, Val Acc: 0.7257\n",
      "Epoch [27/50] Train Loss: 0.0492, Val Loss: 0.9542, Train Acc: 0.9846, Val Acc: 0.7246\n",
      "Epoch [28/50] Train Loss: 0.0465, Val Loss: 0.9620, Train Acc: 0.9856, Val Acc: 0.7246\n",
      "Epoch [29/50] Train Loss: 0.0444, Val Loss: 0.9642, Train Acc: 0.9848, Val Acc: 0.7246\n",
      "Epoch [30/50] Train Loss: 0.0457, Val Loss: 0.9613, Train Acc: 0.9858, Val Acc: 0.7246\n",
      "Epoch [31/50] Train Loss: 0.0492, Val Loss: 0.9634, Train Acc: 0.9823, Val Acc: 0.7257\n",
      "Epoch [32/50] Train Loss: 0.0447, Val Loss: 0.9614, Train Acc: 0.9848, Val Acc: 0.7269\n",
      "Epoch [33/50] Train Loss: 0.0448, Val Loss: 0.9612, Train Acc: 0.9852, Val Acc: 0.7269\n",
      "Epoch [34/50] Train Loss: 0.0441, Val Loss: 0.9600, Train Acc: 0.9846, Val Acc: 0.7257\n",
      "Epoch [35/50] Train Loss: 0.0433, Val Loss: 0.9593, Train Acc: 0.9846, Val Acc: 0.7257\n",
      "Epoch [36/50] Train Loss: 0.0492, Val Loss: 0.9596, Train Acc: 0.9831, Val Acc: 0.7257\n",
      "Epoch [37/50] Train Loss: 0.0481, Val Loss: 0.9594, Train Acc: 0.9844, Val Acc: 0.7257\n",
      "Epoch [38/50] Train Loss: 0.0448, Val Loss: 0.9597, Train Acc: 0.9850, Val Acc: 0.7257\n",
      "Epoch [39/50] Train Loss: 0.0437, Val Loss: 0.9599, Train Acc: 0.9854, Val Acc: 0.7257\n",
      "Epoch [40/50] Train Loss: 0.0440, Val Loss: 0.9596, Train Acc: 0.9858, Val Acc: 0.7257\n",
      "Epoch [41/50] Train Loss: 0.0421, Val Loss: 0.9596, Train Acc: 0.9864, Val Acc: 0.7257\n",
      "Epoch [42/50] Train Loss: 0.0464, Val Loss: 0.9596, Train Acc: 0.9825, Val Acc: 0.7257\n",
      "Epoch [43/50] Train Loss: 0.0498, Val Loss: 0.9596, Train Acc: 0.9816, Val Acc: 0.7257\n",
      "Epoch [44/50] Train Loss: 0.0457, Val Loss: 0.9596, Train Acc: 0.9860, Val Acc: 0.7257\n",
      "Epoch [45/50] Train Loss: 0.0496, Val Loss: 0.9596, Train Acc: 0.9816, Val Acc: 0.7257\n",
      "Epoch [46/50] Train Loss: 0.0453, Val Loss: 0.9596, Train Acc: 0.9844, Val Acc: 0.7257\n",
      "Epoch [47/50] Train Loss: 0.0454, Val Loss: 0.9596, Train Acc: 0.9839, Val Acc: 0.7257\n",
      "Epoch [48/50] Train Loss: 0.0462, Val Loss: 0.9597, Train Acc: 0.9846, Val Acc: 0.7257\n",
      "Epoch [49/50] Train Loss: 0.0452, Val Loss: 0.9597, Train Acc: 0.9854, Val Acc: 0.7257\n",
      "Epoch [50/50] Train Loss: 0.0416, Val Loss: 0.9596, Train Acc: 0.9871, Val Acc: 0.7257\n",
      "Training complete:: \n",
      "Testing Model::\n",
      "size of WB_test_loader :  716928\n",
      "Results: **************************************************\n",
      "Accuracy for Landbird_Land: 0.99\n",
      "Accuracy for Landbird_Water: 0.58\n",
      "Accuracy for Waterbird_Land: 0.22\n",
      "Accuracy for Waterbird_Water: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ahsan/.conda/envs/xAI-bio/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/ahsan/.conda/envs/xAI-bio/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "/tmp/ipykernel_3400215/4283203214.py:268: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"AlexNet-full-model-without-relu_best_model.pth\", map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WB_train_activations save successfully!\n",
      "Epoch [1/100], SAE Loss: 2.0551\n",
      "Epoch [2/100], SAE Loss: 1.0325\n",
      "Epoch [3/100], SAE Loss: 0.9375\n",
      "Epoch [4/100], SAE Loss: 0.9209\n",
      "Epoch [5/100], SAE Loss: 0.8642\n",
      "Epoch [6/100], SAE Loss: 0.8487\n",
      "Epoch [7/100], SAE Loss: 0.7289\n",
      "Epoch [8/100], SAE Loss: 0.7259\n",
      "Epoch [9/100], SAE Loss: 0.8982\n",
      "Epoch [10/100], SAE Loss: 0.7598\n",
      "Epoch [11/100], SAE Loss: 0.6499\n",
      "Epoch [12/100], SAE Loss: 0.6644\n",
      "Epoch [13/100], SAE Loss: 0.6580\n",
      "Epoch [14/100], SAE Loss: 0.6451\n",
      "Epoch [15/100], SAE Loss: 0.5876\n",
      "Epoch [16/100], SAE Loss: 0.6140\n",
      "Epoch [17/100], SAE Loss: 0.5283\n",
      "Epoch [18/100], SAE Loss: 0.5481\n",
      "Epoch [19/100], SAE Loss: 0.5793\n",
      "Epoch [20/100], SAE Loss: 0.5427\n",
      "Epoch [21/100], SAE Loss: 0.5743\n",
      "Epoch [22/100], SAE Loss: 0.5239\n",
      "Epoch [23/100], SAE Loss: 0.5411\n",
      "Epoch [24/100], SAE Loss: 0.6157\n",
      "Epoch [25/100], SAE Loss: 0.5775\n",
      "Epoch [26/100], SAE Loss: 0.4749\n",
      "Epoch [27/100], SAE Loss: 0.5014\n",
      "Epoch [28/100], SAE Loss: 0.5455\n",
      "Epoch [29/100], SAE Loss: 0.5110\n",
      "Epoch [30/100], SAE Loss: 0.4619\n",
      "Epoch [31/100], SAE Loss: 0.5476\n",
      "Epoch [32/100], SAE Loss: 0.5605\n",
      "Epoch [33/100], SAE Loss: 0.4864\n",
      "Epoch [34/100], SAE Loss: 0.4699\n",
      "Epoch [35/100], SAE Loss: 0.4866\n",
      "Epoch [36/100], SAE Loss: 0.5345\n",
      "Epoch [37/100], SAE Loss: 0.5474\n",
      "Epoch [38/100], SAE Loss: 0.5380\n",
      "Epoch [39/100], SAE Loss: 0.5272\n",
      "Epoch [40/100], SAE Loss: 0.4677\n",
      "Epoch [41/100], SAE Loss: 0.5168\n",
      "Epoch [42/100], SAE Loss: 0.4732\n",
      "Epoch [43/100], SAE Loss: 0.4687\n",
      "Epoch [44/100], SAE Loss: 0.5734\n",
      "Epoch [45/100], SAE Loss: 0.5467\n",
      "Epoch [46/100], SAE Loss: 0.4611\n",
      "Epoch [47/100], SAE Loss: 0.5058\n",
      "Epoch [48/100], SAE Loss: 0.4634\n",
      "Epoch [49/100], SAE Loss: 0.4920\n",
      "Epoch [50/100], SAE Loss: 0.5712\n",
      "Epoch [51/100], SAE Loss: 0.4885\n",
      "Epoch [52/100], SAE Loss: 0.4643\n",
      "Epoch [53/100], SAE Loss: 0.4959\n",
      "Epoch [54/100], SAE Loss: 0.5204\n",
      "Epoch [55/100], SAE Loss: 0.4807\n",
      "Epoch [56/100], SAE Loss: 0.4494\n",
      "Epoch [57/100], SAE Loss: 0.4480\n",
      "Epoch [58/100], SAE Loss: 0.4585\n",
      "Epoch [59/100], SAE Loss: 0.4669\n",
      "Epoch [60/100], SAE Loss: 0.5250\n",
      "Epoch [61/100], SAE Loss: 0.4572\n",
      "Epoch [62/100], SAE Loss: 0.4565\n",
      "Epoch [63/100], SAE Loss: 0.4859\n",
      "Epoch [64/100], SAE Loss: 0.5297\n",
      "Epoch [65/100], SAE Loss: 0.5259\n",
      "Epoch [66/100], SAE Loss: 0.5147\n",
      "Epoch [67/100], SAE Loss: 0.4488\n",
      "Epoch [68/100], SAE Loss: 0.4301\n",
      "Epoch [69/100], SAE Loss: 0.4706\n",
      "Epoch [70/100], SAE Loss: 0.5655\n",
      "Epoch [71/100], SAE Loss: 0.5458\n",
      "Epoch [72/100], SAE Loss: 0.4238\n",
      "Epoch [73/100], SAE Loss: 0.4692\n",
      "Epoch [74/100], SAE Loss: 0.5384\n",
      "Epoch [75/100], SAE Loss: 0.5223\n",
      "Epoch [76/100], SAE Loss: 0.4484\n",
      "Epoch [77/100], SAE Loss: 0.5240\n",
      "Epoch [78/100], SAE Loss: 0.4447\n",
      "Epoch [79/100], SAE Loss: 0.4086\n",
      "Epoch [80/100], SAE Loss: 0.4668\n",
      "Epoch [81/100], SAE Loss: 0.5317\n",
      "Epoch [82/100], SAE Loss: 0.5057\n",
      "Epoch [83/100], SAE Loss: 0.5666\n",
      "Epoch [84/100], SAE Loss: 0.4704\n",
      "Epoch [85/100], SAE Loss: 0.4044\n",
      "Epoch [86/100], SAE Loss: 0.4126\n",
      "Epoch [87/100], SAE Loss: 0.5365\n",
      "Epoch [88/100], SAE Loss: 0.4556\n",
      "Epoch [89/100], SAE Loss: 0.4132\n",
      "Epoch [90/100], SAE Loss: 0.4249\n",
      "Epoch [91/100], SAE Loss: 0.4151\n",
      "Epoch [92/100], SAE Loss: 0.4352\n",
      "Epoch [93/100], SAE Loss: 0.4311\n",
      "Epoch [94/100], SAE Loss: 0.4380\n",
      "Epoch [95/100], SAE Loss: 0.5188\n",
      "Epoch [96/100], SAE Loss: 0.5306\n",
      "Epoch [97/100], SAE Loss: 0.4646\n",
      "Epoch [98/100], SAE Loss: 0.4745\n",
      "Epoch [99/100], SAE Loss: 0.5101\n",
      "Epoch [100/100], SAE Loss: 0.4968\n",
      "Training SAE complete!!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, transforms, datasets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import *\n",
    "import PIL.Image\n",
    "from torch.utils.data import DataLoader, DistributedSampler\n",
    "from torchvision.models import AlexNet_Weights, resnet50, ResNet50_Weights, resnet18, ResNet18_Weights, resnet101, ResNet101_Weights, VGG19_Weights, vgg19\n",
    "import torch.distributed as dist\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "# Best settings for most CNN training\n",
    "torch.backends.cudnn.benchmark = True     # Enable auto-tuner\n",
    "torch.backends.cudnn.deterministic = False  # Allow non-deterministic ops\n",
    "torch.backends.cudnn.enabled = True        # Enable cuDNN (default)\n",
    "\n",
    "resnet_writer = SummaryWriter(log_dir='AlexNet-full-model/AlexNet-WB')\n",
    "sae_writer = SummaryWriter(log_dir='AlexNet-full-model/AlexNet-WB')\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.manual_seed(23)\n",
    "np.random.seed(23)\n",
    "\n",
    "class SparseAutoEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, sparsity_lambda=0.7, xavier_norm_init=True):\n",
    "        super(SparseAutoEncoder, self).__init__()\n",
    "        self.sparsity_lambda = sparsity_lambda\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.GroupNorm(num_groups=16, num_channels=hidden_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        if xavier_norm_init:\n",
    "            nn.init.xavier_uniform_(self.encoder[0].weight)  # Xavier initialization\n",
    "            \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, input_dim),\n",
    "            #nn.ReLU() #nn.Sigmoid()  # Output between 0-1\n",
    "        )\n",
    "        if xavier_norm_init:\n",
    "            nn.init.xavier_uniform_(self.decoder[0].weight)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return encoded, decoded\n",
    "    \n",
    "    def kl_sparsity_penalty(self, encoded):\n",
    "        # Penalize the average absolute activation\n",
    "        rho_hat = torch.mean(torch.abs(encoded), dim=0)  # Average absolute activation per hidden unit\n",
    "        rho = torch.ones_like(rho_hat) * self.sparsity_target  # Target sparsity value\n",
    "        epsilon = 1e-8  # Small value to avoid log(0)\n",
    "\n",
    "        # KL-divergence computation for sparsity\n",
    "        kl_divergence = rho * torch.log(rho / (rho_hat + epsilon)) + (1 - rho) * torch.log((1 - rho) / (1 - rho_hat + epsilon))\n",
    "        kl_divergence = torch.sum(kl_divergence)  # Sum over all hidden units\n",
    "\n",
    "        return self.sparsity_lambda * kl_divergence\n",
    "\n",
    "    # L1-norm sparsity penalty calculation\n",
    "    def l1_sparsity_penalty(self, encoded):\n",
    "        # Compute the mean of absolute values of activations\n",
    "        sparsity_loss = torch.mean(torch.abs(encoded))  # Average absolute activation across all units\n",
    "        return self.sparsity_lambda * sparsity_loss  # Scale by the sparsity weight\n",
    "\n",
    "    # Loss function combining MSE (reconstruction error) and sparsity penalty\n",
    "    def loss_function(self, decoded, original, encoded):\n",
    "        mse_loss = F.mse_loss(decoded, original)  # Mean Squared Error for reconstruction\n",
    "        sparsity_loss = self.l1_sparsity_penalty(encoded)  # Sparsity penalty for hidden layer activations\n",
    "        return mse_loss + sparsity_loss  # Total loss is MSE + sparsity penalty\n",
    "\n",
    "# 1. Define Dataset with Metadata\n",
    "class WaterbirdsDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        self.metadata = pd.read_csv(csv_file)  # Metadata file with bird type and background\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.metadata)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = f\"{self.root_dir}/{self.metadata.iloc[idx]['img_filename']}\"\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        bird_type = int(self.metadata.iloc[idx]['y'])  # Waterbird=1, Landbird=0\n",
    "        background = int(self.metadata.iloc[idx]['place'])  # Water=1, Land=0\n",
    "        label = bird_type  # For training, we only care about bird type\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label, bird_type, background\n",
    "        \n",
    "# 2. Transforms and Data Preparation\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load training and testing datasets for WaterBirds_Dataset\n",
    "WB_train_dataset = WaterbirdsDataset(\n",
    "    csv_file = '/home/ahsan/test-project/fss/split-metadata/output_metadata/train_metadata_updated.csv',\n",
    "    #csv_file = '/home/ahsan/test-project/fss/split-metadata/output_metadata/train_metadata_updated_samples.csv',\n",
    "    root_dir= '/home/ahsan/test-project/fss/waterbird_DB/all_images_DB/train_DB/all_birds_train',\n",
    "    transform=transform\n",
    ")\n",
    "WB_test_dataset = WaterbirdsDataset(\n",
    "    csv_file='/home/ahsan/test-project/fss/split-metadata/output_metadata/test_metadata_updated.csv',\n",
    "    root_dir='/home/ahsan/test-project/fss/waterbird_DB/all_images_DB/test_DB/all_birds_test',\n",
    "    transform=transform\n",
    ")\n",
    "WB_val_dataset_WB = WaterbirdsDataset(\n",
    "    csv_file='/home/ahsan/test-project/fss/split-metadata/output_metadata/val_metadata_updated.csv',\n",
    "    root_dir='/home/ahsan/test-project/fss/waterbird_DB/all_images_DB',\n",
    "    transform=transform\n",
    ")\n",
    "batch_size = 128\n",
    "WB_train_loader = DataLoader(WB_train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "WB_test_loader = DataLoader(WB_test_dataset, batch_size=1, shuffle=False, num_workers=4, pin_memory=True)\n",
    "WB_val_loader_WB = DataLoader(WB_val_dataset_WB, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "# 3. Define the AlexNet Model for Binary Classification\n",
    "model = models.alexnet(weights=AlexNet_Weights.IMAGENET1K_V1) \n",
    "# Freeze earlier layers\n",
    "\"\"\"for param in model.features.parameters():\n",
    "    param.requires_grad = False\"\"\"\n",
    "model.classifier[-1] = nn.Linear(4096, 2)\n",
    "model = model.to(device)\n",
    "# 4. Loss and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\"\"\"class_counts = [3693, 1102] #\n",
    "total_samples = sum(class_counts)\n",
    "weights = [total_samples / count for count in class_counts]\n",
    "# Convert to tensor\n",
    "weights_tensor = torch.tensor(weights, dtype=torch.float32).to(device)\n",
    "criterion = torch.nn.CrossEntropyLoss(weight=weights_tensor, label_smoothing=0.1)\n",
    "optimizer = optim.SGD([\n",
    "    {'params': model.features.parameters(), 'lr': 0.0001},\n",
    "    {'params': model.classifier.parameters(), 'lr': 0.001}\n",
    "    ], momentum=0.9, weight_decay=5e-3)\"\"\"\n",
    "optimizer = optim.Adam(model.classifier.parameters(), lr=0.001, weight_decay=5e-3)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=True)\n",
    "#scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
    "# 5. Training Loop\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, writer, num_epochs):\n",
    "    best_val_acc = 0.0\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss, correct, total = 0, 0, 0\n",
    "        for images, labels, _, _ in train_loader:\n",
    "            images, labels = images.to(device=device), labels.to(device=device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            # Apply gradient clipping\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=2.0)\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            correct += (outputs.argmax(1) == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "        \n",
    "        train_loss = total_loss / len(train_loader)\n",
    "        train_acc = correct / total\n",
    "        # Validation... \n",
    "        model.eval()\n",
    "        val_loss, val_correct, val_total = 0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels, _, _ in val_loader:\n",
    "                images, labels = images.to(device=device), labels.to(device=device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                val_correct += (outputs.argmax(1) == labels).sum().item()\n",
    "                val_total += labels.size(0)\n",
    "        val_loss /= len(val_loader)\n",
    "        val_acc = val_correct / val_total\n",
    "        scheduler.step(val_loss)\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "        writer.add_scalar(\"Loss/train\", train_loss, epoch)\n",
    "        writer.add_scalar(\"Loss/val\", val_loss, epoch)\n",
    "        writer.add_scalar(\"Accuracy/train\", train_acc, epoch)\n",
    "        writer.add_scalar(\"Accuracy/val\", val_acc, epoch)\n",
    "        # Save the best model\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), 'AlexNet-full-model-without-relu_best_model.pth')\n",
    "            print(f\"Best model saved at epoch {epoch+1} with Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "print(\"Training AlexNet full-model on WaterBirds dataset:.......................\")\n",
    "print(\"Size of WB_train_loader : \", len(WB_train_loader)*batch_size)\n",
    "train_model(model, WB_train_loader, WB_val_loader_WB, criterion, optimizer, resnet_writer, num_epochs=50)\n",
    "print(\"Training complete:: \")\n",
    "torch.save(model.state_dict(), 'AlexNet-full-model-without-relu_100_epochs.pth')\n",
    "# 6. Testing for Four sub-group Classes\n",
    "def test_model(model, dataloader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model_predictions = []\n",
    "    #with torch.enable_grad():\n",
    "    for images, lables, _, _  in dataloader:\n",
    "        images = images.to(device)\n",
    "        output = model(images)\n",
    "        prediction = torch.argmax(torch.nn.functional.softmax(output, dim=1)).item() # predictions = torch.argmax(outputs, dim=1) \n",
    "        model_predictions.append(prediction)\n",
    "    \n",
    "    print(\"Results:\", \"*\" * 50)\n",
    "    results = {\"Landbird_Land\": 0, \"Landbird_Water\": 0, \"Waterbird_Land\": 0, \"Waterbird_Water\": 0}\n",
    "    counts = {\"Landbird_Land\": 0, \"Landbird_Water\": 0, \"Waterbird_Land\": 0, \"Waterbird_Water\": 0}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for (images, labels, bird_type, background), pred in zip(dataloader, model_predictions):\n",
    "            if bird_type.item() == 0 and background.item() == 0:\n",
    "                results[\"Landbird_Land\"] += (pred == 0)\n",
    "                counts[\"Landbird_Land\"] += 1\n",
    "            elif bird_type.item() == 0 and background.item() == 1:\n",
    "                results[\"Landbird_Water\"] += (pred == 0)\n",
    "                counts[\"Landbird_Water\"] += 1\n",
    "            elif bird_type.item() == 1 and background.item() == 0:\n",
    "                results[\"Waterbird_Land\"] += (pred == 1)\n",
    "                counts[\"Waterbird_Land\"] += 1\n",
    "            elif bird_type.item() == 1 and background.item() == 1:\n",
    "                results[\"Waterbird_Water\"] += (pred == 1)\n",
    "                counts[\"Waterbird_Water\"] += 1\n",
    "\n",
    "        # Calculate accuracies for each group\n",
    "        for key in results:\n",
    "            if counts[key] > 0:\n",
    "                print(f\"Accuracy for {key}: {results[key] / counts[key]:.2f}\")\n",
    "            else:\n",
    "                print(f\"No samples for {key}\")\n",
    "                \n",
    "# Example usage\n",
    "print(\"Testing Model::\")\n",
    "print(\"size of WB_test_loader : \", len(WB_test_loader)*batch_size)\n",
    "test_model(model, WB_test_loader, device=device)\n",
    "\n",
    "# Optional: Save activations (for last layer before fc)\n",
    "def save_activations(model, dataloader, save_path):\n",
    "    model.eval()\n",
    "    activations = []\n",
    "    def hook_fn(module, input, output):\n",
    "        activations.append(output.detach().cpu())\n",
    "    handle = model.classifier[4].register_forward_hook(hook_fn)  # fc2 linear layer (pre-ReLU)\n",
    "    with torch.no_grad():\n",
    "        for images, _, _, _ in dataloader:\n",
    "            model(images.to(device))\n",
    "    handle.remove()\n",
    "    act_tensor = torch.cat(activations, dim=0).squeeze()  # shape: (N, 4096)\n",
    "    np.save(save_path + \".npy\", act_tensor.numpy())\n",
    "    pd.DataFrame(act_tensor.numpy()).to_csv(save_path + \".csv\", index=False)\n",
    "# load best model\n",
    "model = models.alexnet(pretrained=False)\n",
    "model.classifier[-1] = nn.Linear(4096, 2)\n",
    "model.load_state_dict(torch.load(\"AlexNet-full-model-without-relu_best_model.pth\", map_location=device))\n",
    "# Freeze all layers except `classifier[5]` (ReLU) and `classifier[6]` (fc3)\n",
    "for name, param in model.named_parameters():\n",
    "    if name.startswith(\"classifier.6\"):\n",
    "        param.requires_grad = True\n",
    "    elif name.startswith(\"classifier.5\"):  # ReLU does not have trainable params\n",
    "        param.requires_grad = True\n",
    "    else:\n",
    "        param.requires_grad = False\n",
    "# Set the model to evaluation mode\n",
    "model.to(device)\n",
    "model.eval()\n",
    "# Save activations for test set\n",
    "save_activations(model, WB_train_loader, \"AlexNet-full-model-without-relu-activations_100_epochs\")\n",
    "print(\"WB_train_activations save successfully!\")\n",
    "# SAE Train Loop\n",
    "def train_sae(model, data, epochs, lr, batch_size, writer):\n",
    "    model.to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-3)\n",
    "\n",
    "    dataloader = DataLoader(data, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0\n",
    "        for batch in dataloader:\n",
    "            batch = batch[0].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            encoded, decoded = model(batch)\n",
    "            loss = model.loss_function(decoded, batch, encoded)\n",
    "            #loss = criterion(decoded, batch) + sparsity_loss(encoded, sparsity_lambda)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=2.0)\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "        avg_loss = epoch_loss / len(dataloader)\n",
    "        sae_writer.add_scalar(\"Loss/train\", avg_loss, epoch)\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], SAE Loss: {avg_loss:.4f}\")\n",
    "        \n",
    "# Load previously saved activations\n",
    "activations_np = np.load(\"AlexNet-full-model-without-relu-activations_100_epochs.npy\")\n",
    "activations = torch.tensor(activations_np, dtype=torch.float32)\n",
    "# Wrap into a TensorDataset\n",
    "activation_dataset = TensorDataset(activations)\n",
    "# Define model\n",
    "sae = SparseAutoEncoder(input_dim=4096, hidden_dim=8192)\n",
    "train_sae(sae, activation_dataset, epochs=100, lr=0.001, batch_size=128, writer=sae_writer)\n",
    "torch.save(sae.state_dict(), 'AlexNet-full-model-without-relu-SAE_100_epochs.pth')\n",
    "print(\"Training SAE complete!!\")\n",
    "resnet_writer.close()\n",
    "sae_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecbe41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"when freeze earlier layers\"\"\"\n",
    "Accuracy for Landbird_Land: 0.97\n",
    "Accuracy for Landbird_Water: 0.32\n",
    "Accuracy for Waterbird_Land: 0.29\n",
    "Accuracy for Waterbird_Water: 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa27c179",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3139347/3450141046.py:18: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"AlexNet-full-model-without-relu_best_model.pth\", map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WB_train_activations save successfully!\n",
      "Epoch [1/100], SAE Loss: 3.3522\n",
      "Epoch [2/100], SAE Loss: 1.8870\n",
      "Epoch [3/100], SAE Loss: 1.3149\n",
      "Epoch [4/100], SAE Loss: 1.0690\n",
      "Epoch [5/100], SAE Loss: 1.0842\n",
      "Epoch [6/100], SAE Loss: 0.9398\n",
      "Epoch [7/100], SAE Loss: 0.9240\n",
      "Epoch [8/100], SAE Loss: 0.8543\n",
      "Epoch [9/100], SAE Loss: 0.8721\n",
      "Epoch [10/100], SAE Loss: 0.8116\n",
      "Epoch [11/100], SAE Loss: 0.8646\n",
      "Epoch [12/100], SAE Loss: 0.7938\n",
      "Epoch [13/100], SAE Loss: 0.7932\n",
      "Epoch [14/100], SAE Loss: 0.8029\n",
      "Epoch [15/100], SAE Loss: 0.8503\n",
      "Epoch [16/100], SAE Loss: 0.7692\n",
      "Epoch [17/100], SAE Loss: 0.7935\n",
      "Epoch [18/100], SAE Loss: 0.8370\n",
      "Epoch [19/100], SAE Loss: 0.7039\n",
      "Epoch [20/100], SAE Loss: 0.7399\n",
      "Epoch [21/100], SAE Loss: 0.7452\n",
      "Epoch [22/100], SAE Loss: 0.7966\n",
      "Epoch [23/100], SAE Loss: 0.7234\n",
      "Epoch [24/100], SAE Loss: 0.6854\n",
      "Epoch [25/100], SAE Loss: 0.7583\n",
      "Epoch [26/100], SAE Loss: 0.7632\n",
      "Epoch [27/100], SAE Loss: 0.7741\n",
      "Epoch [28/100], SAE Loss: 0.6767\n",
      "Epoch [29/100], SAE Loss: 0.6793\n",
      "Epoch [30/100], SAE Loss: 0.8463\n",
      "Epoch [31/100], SAE Loss: 0.7686\n",
      "Epoch [32/100], SAE Loss: 0.7443\n",
      "Epoch [33/100], SAE Loss: 0.6419\n",
      "Epoch [34/100], SAE Loss: 0.7085\n",
      "Epoch [35/100], SAE Loss: 0.6990\n",
      "Epoch [36/100], SAE Loss: 0.7459\n",
      "Epoch [37/100], SAE Loss: 0.8086\n",
      "Epoch [38/100], SAE Loss: 0.7906\n",
      "Epoch [39/100], SAE Loss: 0.6387\n",
      "Epoch [40/100], SAE Loss: 0.7013\n",
      "Epoch [41/100], SAE Loss: 0.6807\n",
      "Epoch [42/100], SAE Loss: 0.6572\n",
      "Epoch [43/100], SAE Loss: 0.6413\n",
      "Epoch [44/100], SAE Loss: 0.6665\n",
      "Epoch [45/100], SAE Loss: 0.6312\n",
      "Epoch [46/100], SAE Loss: 0.6828\n",
      "Epoch [47/100], SAE Loss: 0.7078\n",
      "Epoch [48/100], SAE Loss: 0.8010\n",
      "Epoch [49/100], SAE Loss: 0.6997\n",
      "Epoch [50/100], SAE Loss: 0.7134\n",
      "Epoch [51/100], SAE Loss: 0.6500\n",
      "Epoch [52/100], SAE Loss: 0.7485\n",
      "Epoch [53/100], SAE Loss: 0.7072\n",
      "Epoch [54/100], SAE Loss: 0.6574\n",
      "Epoch [55/100], SAE Loss: 0.6099\n",
      "Epoch [56/100], SAE Loss: 0.6583\n",
      "Epoch [57/100], SAE Loss: 0.6603\n",
      "Epoch [58/100], SAE Loss: 0.5656\n",
      "Epoch [59/100], SAE Loss: 0.6178\n",
      "Epoch [60/100], SAE Loss: 0.6234\n",
      "Epoch [61/100], SAE Loss: 0.7075\n",
      "Epoch [62/100], SAE Loss: 0.6298\n",
      "Epoch [63/100], SAE Loss: 0.6711\n",
      "Epoch [64/100], SAE Loss: 0.6418\n",
      "Epoch [65/100], SAE Loss: 0.5970\n",
      "Epoch [66/100], SAE Loss: 0.6907\n",
      "Epoch [67/100], SAE Loss: 0.7460\n",
      "Epoch [68/100], SAE Loss: 0.6689\n",
      "Epoch [69/100], SAE Loss: 0.6349\n",
      "Epoch [70/100], SAE Loss: 0.6184\n",
      "Epoch [71/100], SAE Loss: 0.6551\n",
      "Epoch [72/100], SAE Loss: 0.6055\n",
      "Epoch [73/100], SAE Loss: 0.6233\n",
      "Epoch [74/100], SAE Loss: 0.6035\n",
      "Epoch [75/100], SAE Loss: 0.6100\n",
      "Epoch [76/100], SAE Loss: 0.6361\n",
      "Epoch [77/100], SAE Loss: 0.6265\n",
      "Epoch [78/100], SAE Loss: 0.6841\n",
      "Epoch [79/100], SAE Loss: 0.5742\n",
      "Epoch [80/100], SAE Loss: 0.5794\n",
      "Epoch [81/100], SAE Loss: 0.6503\n",
      "Epoch [82/100], SAE Loss: 0.6663\n",
      "Epoch [83/100], SAE Loss: 0.6156\n",
      "Epoch [84/100], SAE Loss: 0.6289\n",
      "Epoch [85/100], SAE Loss: 0.7421\n",
      "Epoch [86/100], SAE Loss: 0.6710\n",
      "Epoch [87/100], SAE Loss: 0.6122\n",
      "Epoch [88/100], SAE Loss: 0.6441\n",
      "Epoch [89/100], SAE Loss: 0.6548\n",
      "Epoch [90/100], SAE Loss: 0.6785\n",
      "Epoch [91/100], SAE Loss: 0.6058\n",
      "Epoch [92/100], SAE Loss: 0.5516\n",
      "Epoch [93/100], SAE Loss: 0.5910\n",
      "Epoch [94/100], SAE Loss: 0.6575\n",
      "Epoch [95/100], SAE Loss: 0.6605\n",
      "Epoch [96/100], SAE Loss: 0.6266\n",
      "Epoch [97/100], SAE Loss: 0.5896\n",
      "Epoch [98/100], SAE Loss: 0.6102\n",
      "Epoch [99/100], SAE Loss: 0.6346\n",
      "Epoch [100/100], SAE Loss: 0.7303\n",
      "Training SAE complete!!\n"
     ]
    }
   ],
   "source": [
    "# Save activations (for last layer before fc)\n",
    "def save_activations(model, dataloader, save_path):\n",
    "    model.eval()\n",
    "    activations = []\n",
    "    def hook_fn(module, input, output):\n",
    "        activations.append(output.detach().cpu())\n",
    "    handle = model.classifier[4].register_forward_hook(hook_fn)  # fc2 linear layer (pre-ReLU)\n",
    "    with torch.no_grad():\n",
    "        for images, _, _, _ in dataloader:\n",
    "            model(images.to(device))\n",
    "    handle.remove()\n",
    "    act_tensor = torch.cat(activations, dim=0).squeeze()  # shape: (N, 4096)\n",
    "    np.save(save_path + \".npy\", act_tensor.numpy())\n",
    "    pd.DataFrame(act_tensor.numpy()).to_csv(save_path + \".csv\", index=False)\n",
    "# load best model\n",
    "model = models.alexnet(weights=None)\n",
    "model.classifier[6] = nn.Linear(4096, 2)\n",
    "model.load_state_dict(torch.load(\"AlexNet-full-model-without-relu_best_model.pth\", map_location=device))\n",
    "# Freeze all layers except `classifier[5]` (ReLU) and `classifier[6]` (fc3)\n",
    "\"\"\" for name, param in model.named_parameters():\n",
    "    if name.startswith(\"classifier.6\"):\n",
    "        param.requires_grad = True\n",
    "    elif name.startswith(\"classifier.5\"):  # ReLU does not have trainable params\n",
    "        param.requires_grad = True\n",
    "    else:\n",
    "        param.requires_grad = False\n",
    "# Set the model to evaluation mode \"\"\"\n",
    "model.eval()\n",
    "model.to(device)\n",
    "# Save activations for test set\n",
    "save_activations(model, WB_train_loader, \"AlexNet-full-model-without-relu-activations_100_epochs\")\n",
    "print(\"WB_train_activations save successfully!\")\n",
    "# SAE Train Loop\n",
    "def train_sae(model, data, epochs, lr, batch_size, writer):\n",
    "    model.to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-3)\n",
    "    dataloader = DataLoader(data, batch_size=batch_size, shuffle=True)\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0\n",
    "        for batch in dataloader:\n",
    "            batch = batch[0].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            encoded, decoded = model(batch)\n",
    "            loss = model.loss_function(decoded, batch, encoded)\n",
    "            #loss = criterion(decoded, batch) + sparsity_loss(encoded, sparsity_lambda)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=2.0)\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "        avg_loss = epoch_loss / len(dataloader)\n",
    "        sae_writer.add_scalar(\"Loss/train\", avg_loss, epoch)\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], SAE Loss: {avg_loss:.4f}\")\n",
    "        \n",
    "# Load previously saved activations\n",
    "activations_np = np.load(\"AlexNet-full-model-without-relu-activations_100_epochs.npy\")\n",
    "activations = torch.tensor(activations_np, dtype=torch.float32)\n",
    "# Wrap into a TensorDataset\n",
    "activation_dataset = TensorDataset(activations)\n",
    "# Define model\n",
    "sae = SparseAutoEncoder(input_dim=4096, hidden_dim=8192)\n",
    "train_sae(sae, activation_dataset, epochs=100, lr=0.001, batch_size=128, writer=sae_writer)\n",
    "torch.save(sae.state_dict(), 'AlexNet-full-model-without-relu-SAE_100_epochs.pth')\n",
    "print(\"Training SAE complete!!\")\n",
    "resnet_writer.close() \n",
    "sae_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d6468c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Model::\n",
      "size of WB_test_loader :  5601\n",
      "Results: **************************************************\n",
      "Accuracy for Landbird_Land: 0.99 (2229/2255)\n",
      "Accuracy for Landbird_Water: 0.58 (1188/2062)\n",
      "Accuracy for Waterbird_Land: 0.24 (151/642)\n",
      "Accuracy for Waterbird_Water: 0.89 (571/642)\n"
     ]
    }
   ],
   "source": [
    "def test_model(model, dataloader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model_predictions = []\n",
    "    #with torch.enable_grad():\n",
    "    for images, lables, _, _  in dataloader:\n",
    "        images = images.to(device)\n",
    "        output = model(images)\n",
    "        prediction = torch.argmax(torch.nn.functional.softmax(output, dim=1)).item() # predictions = torch.argmax(outputs, dim=1) \n",
    "        model_predictions.append(prediction)\n",
    "    \n",
    "    print(\"Results:\", \"*\" * 50)\n",
    "    results = {\"Landbird_Land\": 0, \"Landbird_Water\": 0, \"Waterbird_Land\": 0, \"Waterbird_Water\": 0}\n",
    "    counts = {\"Landbird_Land\": 0, \"Landbird_Water\": 0, \"Waterbird_Land\": 0, \"Waterbird_Water\": 0}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for (images, labels, bird_type, background), pred in zip(dataloader, model_predictions):\n",
    "            if bird_type.item() == 0 and background.item() == 0:\n",
    "                results[\"Landbird_Land\"] += (pred == 0)\n",
    "                counts[\"Landbird_Land\"] += 1\n",
    "            elif bird_type.item() == 0 and background.item() == 1:\n",
    "                results[\"Landbird_Water\"] += (pred == 0)\n",
    "                counts[\"Landbird_Water\"] += 1\n",
    "            elif bird_type.item() == 1 and background.item() == 0:\n",
    "                results[\"Waterbird_Land\"] += (pred == 1)\n",
    "                counts[\"Waterbird_Land\"] += 1\n",
    "            elif bird_type.item() == 1 and background.item() == 1:\n",
    "                results[\"Waterbird_Water\"] += (pred == 1)\n",
    "                counts[\"Waterbird_Water\"] += 1\n",
    "\n",
    "        # Calculate accuracies for each group\n",
    "        for key in results:\n",
    "            if counts[key] > 0:\n",
    "                print(f\"Accuracy for {key}: {results[key] / counts[key]:.2f} ({results[key]}/{counts[key]})\")\n",
    "            else:\n",
    "                print(f\"No samples for {key}\")\n",
    "                \n",
    "# Example usage\n",
    "print(\"Testing Model::\")\n",
    "print(\"size of WB_test_loader : \", len(WB_test_loader))\n",
    "test_model(model, WB_test_loader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef2781d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Model::\n",
      "size of WB_test_loader :  5601\n",
      "\n",
      "Results: **************************************************\n",
      "Accuracy for Landbird_Land: 0.99 (2229/2255)\n",
      "Accuracy for Landbird_Water: 0.58 (1188/2062)\n",
      "Accuracy for Waterbird_Land: 0.24 (151/642)\n",
      "Accuracy for Waterbird_Water: 0.89 (571/642)\n"
     ]
    }
   ],
   "source": [
    "def test_model(model, dataloader, device):\n",
    "    model.eval()\n",
    "    \n",
    "    results = {\"Landbird_Land\": 0, \"Landbird_Water\": 0, \"Waterbird_Land\": 0, \"Waterbird_Water\": 0}\n",
    "    counts = {\"Landbird_Land\": 0, \"Landbird_Water\": 0, \"Waterbird_Land\": 0, \"Waterbird_Water\": 0}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels, bird_type, background in dataloader:\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            predictions = torch.argmax(outputs, dim=1).cpu()\n",
    "            bird_type = bird_type.cpu()\n",
    "            background = background.cpu()\n",
    "\n",
    "            for i in range(len(predictions)):\n",
    "                b_type = bird_type[i].item()\n",
    "                bg = background[i].item()\n",
    "                pred = predictions[i].item()\n",
    "\n",
    "                if b_type == 0 and bg == 0:\n",
    "                    results[\"Landbird_Land\"] += (pred == 0)\n",
    "                    counts[\"Landbird_Land\"] += 1\n",
    "                elif b_type == 0 and bg == 1:\n",
    "                    results[\"Landbird_Water\"] += (pred == 0)\n",
    "                    counts[\"Landbird_Water\"] += 1\n",
    "                elif b_type == 1 and bg == 0:\n",
    "                    results[\"Waterbird_Land\"] += (pred == 1)\n",
    "                    counts[\"Waterbird_Land\"] += 1\n",
    "                elif b_type == 1 and bg == 1:\n",
    "                    results[\"Waterbird_Water\"] += (pred == 1)\n",
    "                    counts[\"Waterbird_Water\"] += 1\n",
    "\n",
    "    # Accuracy results\n",
    "    print(\"\\nResults:\", \"*\" * 50)\n",
    "    for key in results:\n",
    "        if counts[key] > 0:\n",
    "            accuracy = results[key] / counts[key]\n",
    "            print(f\"Accuracy for {key}: {accuracy:.2f} ({results[key]}/{counts[key]})\")\n",
    "        else:\n",
    "            print(f\"No samples for {key}\")\n",
    "\n",
    "# Example usage\n",
    "print(\"Testing Model::\")\n",
    "print(\"size of WB_test_loader : \", len(WB_test_loader))\n",
    "test_model(model, WB_test_loader, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4e180a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xAI-bio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
