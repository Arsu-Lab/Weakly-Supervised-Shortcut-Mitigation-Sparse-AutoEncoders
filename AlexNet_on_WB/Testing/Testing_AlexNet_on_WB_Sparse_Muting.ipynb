{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a911f29-6c62-44a3-81a4-7a47612d3477",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader, random_split, Subset\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "from torchvision.models import alexnet, AlexNet_Weights, resnet50, ResNet50_Weights, resnet18, ResNet18_Weights, resnet101, ResNet101_Weights, VGG19_Weights, vgg19\n",
    "from PIL import *\n",
    "import PIL.Image\n",
    "import gc\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.manual_seed(23)\n",
    "np.random.seed(23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f3cd939-8b3e-4dfc-815c-5e8118bbf938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define Datasets and Dataloader\n",
    "class WaterbirdsDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        self.metadata = pd.read_csv(csv_file)  # Metadata file with bird type and background\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.metadata)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = f\"{self.root_dir}/{self.metadata.iloc[idx]['img_filename']}\"\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        bird_type = self.metadata.iloc[idx]['y']  # Waterbird=1, Landbird=0\n",
    "        background = self.metadata.iloc[idx]['place']  # Water=1, Land=0\n",
    "        label = bird_type  # For training, we only care about bird type\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label, bird_type, background\n",
    "\n",
    "# 2. Transforms and Data Preparation\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load training and testing datasets\n",
    "train_dataset = WaterbirdsDataset(\n",
    "    csv_file='/run/determined/workdir/SCLearning_WB/split-metadata/output_metadata/train_metadata_updated.csv',\n",
    "    root_dir='/run/determined/workdir/SCLearning_WB/WB_DB/all_images_DB/train_DB/all_birds_train',\n",
    "    transform=transform\n",
    ")\n",
    "test_dataset = WaterbirdsDataset(\n",
    "    csv_file='/run/determined/workdir/SCLearning_WB/split-metadata/output_metadata/test_metadata_updated.csv',\n",
    "    root_dir='/run/determined/workdir/SCLearning_WB/WB_DB/all_images_DB/test_DB/all_birds_test',\n",
    "    transform=transform\n",
    ")\n",
    "test_dataset_LB = WaterbirdsDataset(\n",
    "    csv_file='/run/determined/workdir/SCLearning_WB/split-metadata/output_metadata/test_metadata_updated_LB.csv',\n",
    "    root_dir='/run/determined/workdir/SCLearning_WB/WB_DB/all_images_DB/test_DB/all_birds_test',\n",
    "    transform=transform\n",
    ")\n",
    "test_dataset_LB_no_patch = WaterbirdsDataset(\n",
    "    csv_file='/run/determined/workdir/SCLearning_WB/split-metadata/output_metadata/test_metadata_updated_LB_no_patch.csv',\n",
    "    root_dir='/run/determined/workdir/SCLearning_WB/WB_DB/all_images_DB/test_DB/all_birds_test',\n",
    "    transform=transform\n",
    ")\n",
    "test_dataset_LB_patch = WaterbirdsDataset(\n",
    "    csv_file='/run/determined/workdir/SCLearning_WB/split-metadata/output_metadata/test_metadata_updated_LB_patch.csv',\n",
    "    root_dir='/run/determined/workdir/SCLearning_WB/WB_DB/all_images_DB/test_DB/all_birds_test',\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "test_dataset_LB_25 = WaterbirdsDataset(\n",
    "    csv_file='/run/determined/workdir/SCLearning_WB/split-metadata/output_metadata/test_metadata_updated_LB_25.csv',\n",
    "    root_dir='/run/determined/workdir/SCLearning_WB/WB_DB/all_images_DB/test_DB/all_birds_test',\n",
    "    transform=transform\n",
    ")\n",
    "test_dataset_WB = WaterbirdsDataset(\n",
    "    csv_file='/run/determined/workdir/SCLearning_WB/split-metadata/output_metadata/test_metadata_updated_WB.csv',\n",
    "    root_dir='/run/determined/workdir/SCLearning_WB/WB_DB/all_images_DB/test_DB/all_birds_test',\n",
    "    transform=transform\n",
    ")\n",
    "test_dataset_WB_no_patch = WaterbirdsDataset(\n",
    "    csv_file='/run/determined/workdir/SCLearning_WB/split-metadata/output_metadata/test_metadata_updated_WB_no_patch.csv',\n",
    "    root_dir='/run/determined/workdir/SCLearning_WB/WB_DB/all_images_DB/test_DB/all_birds_test',\n",
    "    transform=transform\n",
    ")\n",
    "test_dataset_WB_patch = WaterbirdsDataset(\n",
    "    csv_file='/run/determined/workdir/SCLearning_WB/split-metadata/output_metadata/test_metadata_updated_WB_patch.csv',\n",
    "    root_dir='/run/determined/workdir/SCLearning_WB/WB_DB/all_images_DB/test_DB/all_birds_test',\n",
    "    transform=transform\n",
    ") \n",
    "test_dataset_WB_25 = WaterbirdsDataset(\n",
    "    csv_file='/run/determined/workdir/SCLearning_WB/split-metadata/output_metadata/test_metadata_updated_WB_25.csv',\n",
    "    root_dir='/run/determined/workdir/SCLearning_WB/WB_DB/all_images_DB/test_DB/all_birds_test',\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "val_dataset_LB = WaterbirdsDataset(\n",
    "    #csv_file='/run/determined/workdir/SCLearning_WB/split-metadata/output_metadata/val_metadata_updated_LB.csv',\n",
    "    csv_file='/run/determined/workdir/SCLearning_WB/split-metadata/output_metadata/val_metadata_0_1_LB.csv',\n",
    "    root_dir='/run/determined/workdir/SCLearning_WB/WB_DB/all_images_DB',\n",
    "    transform=transform\n",
    ")\n",
    "val_dataset_WB = WaterbirdsDataset(\n",
    "    csv_file='/run/determined/workdir/SCLearning_WB/split-metadata/output_metadata/val_metadata_updated_WB.csv',\n",
    "    root_dir='/run/determined/workdir/SCLearning_WB/WB_DB/all_images_DB',\n",
    "    transform=transform\n",
    ")\n",
    "val_dataset_WB_LB = WaterbirdsDataset(\n",
    "    csv_file='/run/determined/workdir/SCLearning_WB/split-metadata/output_metadata/val_metadata_WB+LB.csv',\n",
    "    root_dir='/run/determined/workdir/SCLearning_WB/WB_DB/all_images_DB',\n",
    "    transform=transform\n",
    ")\n",
    "# Variational DB\n",
    "val_dataset_LB_25 = WaterbirdsDataset(\n",
    "    csv_file='/run/determined/workdir/SCLearning_WB/split-metadata/output_metadata/val_metadata_updated_LB_yes_no_25.csv',\n",
    "    #csv_file='/run/determined/workdir/SCLearning_WB/split-metadata/output_metadata/val_metadata_0_1_LB.csv',\n",
    "    root_dir='/run/determined/workdir/SCLearning_WB/WB_DB/all_images_DB',\n",
    "    transform=transform\n",
    ")\n",
    "val_dataset_LB_no_patch_25 = WaterbirdsDataset(\n",
    "    csv_file='/run/determined/workdir/SCLearning_WB/split-metadata/output_metadata/val_metadata_updated_LB_no_patch_25.csv',\n",
    "    #csv_file='/run/determined/workdir/SCLearning_WB/split-metadata/output_metadata/val_metadata_0_1_LB.csv',\n",
    "    root_dir='/run/determined/workdir/SCLearning_WB/WB_DB/all_images_DB',\n",
    "    transform=transform\n",
    ")\n",
    "val_dataset_LB_patch_25 = WaterbirdsDataset(\n",
    "    csv_file='/run/determined/workdir/SCLearning_WB/split-metadata/output_metadata/val_metadata_updated_LB_patch_25.csv',\n",
    "    #csv_file='/run/determined/workdir/SCLearning_WB/split-metadata/output_metadata/val_metadata_0_1_LB.csv',\n",
    "    root_dir='/run/determined/workdir/SCLearning_WB/WB_DB/all_images_DB',\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "val_dataset_WB_25 = WaterbirdsDataset(\n",
    "    csv_file='/run/determined/workdir/SCLearning_WB/split-metadata/output_metadata/val_metadata_updated_WB_yes_no_25.csv',\n",
    "    root_dir='/run/determined/workdir/SCLearning_WB/WB_DB/all_images_DB',\n",
    "    transform=transform\n",
    ")\n",
    "val_dataset_WB_no_patch_25 = WaterbirdsDataset(\n",
    "    csv_file='/run/determined/workdir/SCLearning_WB/split-metadata/output_metadata/val_metadata_updated_WB_no_patch_25.csv',\n",
    "    root_dir='/run/determined/workdir/SCLearning_WB/WB_DB/all_images_DB',\n",
    "    transform=transform\n",
    ")\n",
    "val_dataset_WB_patch_25 = WaterbirdsDataset(\n",
    "    csv_file='/run/determined/workdir/SCLearning_WB/split-metadata/output_metadata/val_metadata_updated_WB_patch_25.csv',\n",
    "    root_dir='/run/determined/workdir/SCLearning_WB/WB_DB/all_images_DB',\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "val_dataset_LB_50 = WaterbirdsDataset(\n",
    "    csv_file='/run/determined/workdir/SCLearning_WB/split-metadata/output_metadata/val_metadata_updated_LB_yes_no_50.csv',\n",
    "    #csv_file='/run/determined/workdir/SCLearning_WB/split-metadata/output_metadata/val_metadata_0_1_LB.csv',\n",
    "    root_dir='/run/determined/workdir/SCLearning_WB/WB_DB/all_images_DB',\n",
    "    transform=transform\n",
    ")\n",
    "val_dataset_LB_no_patch_50 = WaterbirdsDataset(\n",
    "    csv_file='/run/determined/workdir/SCLearning_WB/split-metadata/output_metadata/val_metadata_updated_LB_no_patch_50.csv',\n",
    "    #csv_file='/run/determined/workdir/SCLearning_WB/split-metadata/output_metadata/val_metadata_0_1_LB.csv',\n",
    "    root_dir='/run/determined/workdir/SCLearning_WB/WB_DB/all_images_DB',\n",
    "    transform=transform\n",
    ")\n",
    "val_dataset_LB_patch_50 = WaterbirdsDataset(\n",
    "    csv_file='/run/determined/workdir/SCLearning_WB/split-metadata/output_metadata/val_metadata_updated_LB_patch_50.csv',\n",
    "    #csv_file='/run/determined/workdir/SCLearning_WB/split-metadata/output_metadata/val_metadata_0_1_LB.csv',\n",
    "    root_dir='/run/determined/workdir/SCLearning_WB/WB_DB/all_images_DB',\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "val_dataset_WB_50 = WaterbirdsDataset(\n",
    "    csv_file='/run/determined/workdir/SCLearning_WB/split-metadata/output_metadata/val_metadata_updated_WB_yes_no_50.csv',\n",
    "    root_dir='/run/determined/workdir/SCLearning_WB/WB_DB/all_images_DB',\n",
    "    transform=transform\n",
    ")\n",
    "val_dataset_WB_no_patch_50 = WaterbirdsDataset(\n",
    "    csv_file='/run/determined/workdir/SCLearning_WB/split-metadata/output_metadata/val_metadata_updated_WB_no_patch_50.csv',\n",
    "    root_dir='/run/determined/workdir/SCLearning_WB/WB_DB/all_images_DB',\n",
    "    transform=transform\n",
    ")\n",
    "val_dataset_WB_patch_50 = WaterbirdsDataset(\n",
    "    csv_file='/run/determined/workdir/SCLearning_WB/split-metadata/output_metadata/val_metadata_updated_WB_patch_50.csv',\n",
    "    root_dir='/run/determined/workdir/SCLearning_WB/WB_DB/all_images_DB',\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "\n",
    "val_dataset_LB_100 = WaterbirdsDataset(\n",
    "    csv_file='/run/determined/workdir/SCLearning_WB/split-metadata/output_metadata/val_metadata_updated_LB_yes_no_100.csv',\n",
    "    #csv_file='/run/determined/workdir/SCLearning_WB/split-metadata/output_metadata/val_metadata_0_1_LB.csv',\n",
    "    root_dir='/run/determined/workdir/SCLearning_WB/WB_DB/all_images_DB',\n",
    "    transform=transform\n",
    ")\n",
    "val_dataset_LB_patch_100 = WaterbirdsDataset(\n",
    "    csv_file='/run/determined/workdir/SCLearning_WB/split-metadata/output_metadata/val_metadata_updated_LB_patch_100.csv',\n",
    "    #csv_file='/run/determined/workdir/SCLearning_WB/split-metadata/output_metadata/val_metadata_0_1_LB.csv',\n",
    "    root_dir='/run/determined/workdir/SCLearning_WB/WB_DB/all_images_DB',\n",
    "    transform=transform\n",
    ")\n",
    "val_dataset_LB_no_patch_100 = WaterbirdsDataset(\n",
    "    csv_file='/run/determined/workdir/SCLearning_WB/split-metadata/output_metadata/val_metadata_updated_LB_no_patch_100.csv',\n",
    "    #csv_file='/run/determined/workdir/SCLearning_WB/split-metadata/output_metadata/val_metadata_0_1_LB.csv',\n",
    "    root_dir='/run/determined/workdir/SCLearning_WB/WB_DB/all_images_DB',\n",
    "    transform=transform\n",
    ")\n",
    "val_dataset_WB_100 = WaterbirdsDataset(\n",
    "    csv_file='/run/determined/workdir/SCLearning_WB/split-metadata/output_metadata/val_metadata_updated_WB_yes_no_100.csv',\n",
    "    root_dir='/run/determined/workdir/SCLearning_WB/WB_DB/all_images_DB',\n",
    "    transform=transform\n",
    ")\n",
    "val_dataset_WB_patch_100 = WaterbirdsDataset(\n",
    "    csv_file='/run/determined/workdir/SCLearning_WB/split-metadata/output_metadata/val_metadata_updated_WB_patch_100.csv',\n",
    "    root_dir='/run/determined/workdir/SCLearning_WB/WB_DB/all_images_DB',\n",
    "    transform=transform\n",
    ")\n",
    "val_dataset_WB_no_patch_100 = WaterbirdsDataset(\n",
    "    csv_file='/run/determined/workdir/SCLearning_WB/split-metadata/output_metadata/val_metadata_updated_WB_no_patch_100.csv',\n",
    "    root_dir='/run/determined/workdir/SCLearning_WB/WB_DB/all_images_DB',\n",
    "    transform=transform\n",
    ")\n",
    "val_dataset_LB_200 = WaterbirdsDataset(\n",
    "    csv_file='/run/determined/workdir/SCLearning_WB/split-metadata/output_metadata/val_metadata_updated_LB_yes_no_200.csv',\n",
    "    #csv_file='/run/determined/workdir/SCLearning_WB/split-metadata/output_metadata/val_metadata_0_1_LB.csv',\n",
    "    root_dir='/run/determined/workdir/SCLearning_WB/WB_DB/all_images_DB',\n",
    "    transform=transform\n",
    ")\n",
    "val_dataset_LB_patch_200 = WaterbirdsDataset(\n",
    "    csv_file='/run/determined/workdir/SCLearning_WB/split-metadata/output_metadata/val_metadata_updated_LB_patch_200.csv',\n",
    "    #csv_file='/run/determined/workdir/SCLearning_WB/split-metadata/output_metadata/val_metadata_0_1_LB.csv',\n",
    "    root_dir='/run/determined/workdir/SCLearning_WB/WB_DB/all_images_DB',\n",
    "    transform=transform\n",
    ")\n",
    "val_dataset_LB_no_patch_200 = WaterbirdsDataset(\n",
    "    csv_file='/run/determined/workdir/SCLearning_WB/split-metadata/output_metadata/val_metadata_updated_LB_no_patch_200.csv',\n",
    "    #csv_file='/run/determined/workdir/SCLearning_WB/split-metadata/output_metadata/val_metadata_0_1_LB.csv',\n",
    "    root_dir='/run/determined/workdir/SCLearning_WB/WB_DB/all_images_DB',\n",
    "    transform=transform\n",
    ")\n",
    "val_dataset_WB_200 = WaterbirdsDataset(\n",
    "    csv_file='/run/determined/workdir/SCLearning_WB/split-metadata/output_metadata/val_metadata_updated_WB_yes_no_200.csv',\n",
    "    root_dir='/run/determined/workdir/SCLearning_WB/WB_DB/all_images_DB',\n",
    "    transform=transform\n",
    ")\n",
    "val_dataset_WB_patch_200 = WaterbirdsDataset(\n",
    "    csv_file='/run/determined/workdir/SCLearning_WB/split-metadata/output_metadata/val_metadata_updated_WB_patch_200.csv',\n",
    "    root_dir='/run/determined/workdir/SCLearning_WB/WB_DB/all_images_DB',\n",
    "    transform=transform\n",
    ")\n",
    "val_dataset_WB_no_patch_200 = WaterbirdsDataset(\n",
    "    csv_file='/run/determined/workdir/SCLearning_WB/split-metadata/output_metadata/val_metadata_updated_WB_no_patch_200.csv',\n",
    "    root_dir='/run/determined/workdir/SCLearning_WB/WB_DB/all_images_DB',\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "batch_size = 128\n",
    "val_loader_LB_25 = DataLoader(val_dataset_LB_25, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "val_loader_WB_25 = DataLoader(val_dataset_WB_25, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "val_loader_LB_50 = DataLoader(val_dataset_LB_50, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "val_loader_WB_50 = DataLoader(val_dataset_WB_50, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "val_loader_LB_100 = DataLoader(val_dataset_LB_100, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "val_loader_WB_100 = DataLoader(val_dataset_WB_100, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "val_loader_LB_200 = DataLoader(val_dataset_LB_200, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "val_loader_WB_200 = DataLoader(val_dataset_WB_200, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "test_loader_LB = DataLoader(test_dataset_LB, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "test_loader_LB_25 = DataLoader(test_dataset_LB_25, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "test_loader_WB = DataLoader(test_dataset_WB, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "test_loader_WB_25 = DataLoader(test_dataset_WB_25, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "test_Loader_LB_no_patch = DataLoader(test_dataset_LB_no_patch, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "test_Loader_LB_patch = DataLoader(test_dataset_LB_patch, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "test_Loader_WB_no_patch = DataLoader(test_dataset_WB_no_patch, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "test_Loader_WB_patch = DataLoader(test_dataset_WB_patch, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "\n",
    "val_Loader_LB_no_patch_200 = DataLoader(val_dataset_LB_no_patch_200, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_Loader_LB_patch_200 = DataLoader(val_dataset_LB_patch_200, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_Loader_WB_no_patch_200 = DataLoader(val_dataset_WB_no_patch_200, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_Loader_WB_patch_200 = DataLoader(val_dataset_WB_patch_200, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "\n",
    "val_Loader_LB_no_patch_100 = DataLoader(val_dataset_LB_no_patch_100, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_Loader_LB_patch_100 = DataLoader(val_dataset_LB_patch_100, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_Loader_WB_no_patch_100 = DataLoader(val_dataset_WB_no_patch_100, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_Loader_WB_patch_100 = DataLoader(val_dataset_WB_patch_100, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "\n",
    "val_Loader_LB_no_patch_50 = DataLoader(val_dataset_LB_no_patch_50, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_Loader_LB_patch_50 = DataLoader(val_dataset_LB_patch_50, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_Loader_WB_no_patch_50 = DataLoader(val_dataset_WB_no_patch_50, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_Loader_WB_patch_50 = DataLoader(val_dataset_WB_patch_50, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "\n",
    "val_Loader_LB_no_patch_25 = DataLoader(val_dataset_LB_no_patch_25, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_Loader_LB_patch_25 = DataLoader(val_dataset_LB_patch_25, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_Loader_WB_no_patch_25 = DataLoader(val_dataset_WB_no_patch_25, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_Loader_WB_patch_25 = DataLoader(val_dataset_WB_patch_25, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "\n",
    "val_loader_LB = DataLoader(val_dataset_LB, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "val_loader_WB = DataLoader(val_dataset_WB, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "val_loader_WB_LB = DataLoader(val_dataset_WB_LB, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "891985f7-4652-4adb-bb4f-cdd0fd0d5fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparseAutoEncoder_2(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, sparsity_lambda=0.7, xavier_norm_init=True):\n",
    "        super(SparseAutoEncoder_2, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.sparsity_lambda = sparsity_lambda\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(self.input_dim, self.hidden_dim),\n",
    "            nn.GroupNorm(num_groups=2, num_channels=hidden_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        if xavier_norm_init:\n",
    "            nn.init.xavier_uniform_(self.encoder[0].weight)  # Xavier initialization\n",
    "            \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(self.hidden_dim, self.input_dim),\n",
    "            #nn.ReLU() #nn.Sigmoid()  # Output between 0-1\n",
    "        )\n",
    "        if xavier_norm_init:\n",
    "            nn.init.xavier_uniform_(self.decoder[0].weight)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return encoded, decoded\n",
    "    \n",
    "    def kl_sparsity_penalty(self, encoded):\n",
    "        # Penalize the average absolute activation\n",
    "        rho_hat = torch.mean(torch.abs(encoded), dim=0)  # Average absolute activation per hidden unit\n",
    "        #rho_hat = 0.1122\n",
    "        rho = torch.ones_like(rho_hat) * self.sparsity_target  # Target sparsity value\n",
    "        epsilon = 1e-8  # Small value to avoid log(0)\n",
    "\n",
    "        # KL-divergence computation for sparsity\n",
    "        kl_divergence = rho * torch.log(rho / (rho_hat + epsilon)) + (1 - rho) * torch.log((1 - rho) / (1 - rho_hat + epsilon))\n",
    "        kl_divergence = torch.sum(kl_divergence)  # Sum over all hidden units\n",
    "\n",
    "        return self.sparsity_lambda * kl_divergence\n",
    "\n",
    "    # L1-norm sparsity penalty calculation\n",
    "    def l1_sparsity_penalty(self, encoded):\n",
    "        # Compute the mean of absolute values of activations\n",
    "        sparsity_loss = torch.mean(torch.abs(encoded))  # Average absolute activation across all units\n",
    "        #sparsity_loss = 0.1122  # Average absolute activation across all units\n",
    "        return self.sparsity_lambda * sparsity_loss  # Scale by the sparsity weight\n",
    "\n",
    "    # Loss function combining MSE (reconstruction error) and sparsity penalty\n",
    "    def loss_function(self, decoded, original, encoded):\n",
    "        mse_loss = F.mse_loss(decoded, original)  # Mean Squared Error for reconstruction\n",
    "        sparsity_loss = self.l1_sparsity_penalty(encoded)  # Sparsity penalty for hidden layer activations\n",
    "        return mse_loss + sparsity_loss  # Total loss is MSE + sparsity penalty\n",
    "# Instantiate the Sparse Auto-encoder with given dimensions\n",
    "def load_autoencoder_2(sae_path, device):\n",
    "    input_dim = 4096 \n",
    "    hidden_dim = 8192\n",
    "    sae_2 = SparseAutoEncoder_2(input_dim, hidden_dim)\n",
    "    sae_2.load_state_dict(torch.load(sae_path, map_location=device))\n",
    "    sae_2 = sae_2.to(device)\n",
    "    # Freeze all parameters of the autoencoder\n",
    "    for param in sae_2.parameters():\n",
    "        param.requires_grad = False\n",
    "    sae_2.eval()\n",
    "    return sae_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6d0583b9-d605-46b9-b821-d360583eccab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Models\n",
    "def get_model_AlexNet(model_path, device):\n",
    "    num_features = 4096\n",
    "    num_classes = 2\n",
    "    model_path = model_path\n",
    "    device = device\n",
    "    \n",
    "    model = alexnet(weights=None) # weights=AlexNet_Weights.DEFAULT) # weights=None\n",
    "    model.classifier[6] = nn.Linear(4096, 2)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model = model.to(device)\n",
    "    # Freeze all layers except `classifier[5]` (ReLU) and `classifier[6]` (fc3)\n",
    "    for name, param in model.named_parameters():\n",
    "        if name.startswith(\"classifier.6\"):\n",
    "            param.requires_grad = True\n",
    "        elif name.startswith(\"classifier.5\"):  # ReLU does not have trainable params\n",
    "            param.requires_grad = True\n",
    "        else:\n",
    "            param.requires_grad = False\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1d88c239-b2f0-43e2-a8db-b149f9690f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_and_align_activations(activations_list):\n",
    "    flat_activations = [act.flatten() for act in activations_list]\n",
    "    max_length = max(len(act) for act in flat_activations)\n",
    "\n",
    "    aligned_activations = []\n",
    "    for activation in flat_activations:\n",
    "        if len(activation) < max_length:\n",
    "            padded_activation = np.pad(activation, (0, max_length - len(activation)), 'constant')\n",
    "        else:\n",
    "            padded_activation = activation[:max_length]\n",
    "        aligned_activations.append(padded_activation)\n",
    "    return np.vstack(aligned_activations)\n",
    "\n",
    "def get_activations_AlexNet(model, dataloader, device):\n",
    "    model.eval()\n",
    "    activations = []\n",
    "    def hook_fn(module, input, output):\n",
    "        activations.append(output.detach().cpu())\n",
    "    handle = model.classifier[4].register_forward_hook(hook_fn)  # fc2 linear layer (pre-ReLU)\n",
    "    with torch.no_grad():\n",
    "        for images, _, _, _ in dataloader:\n",
    "            _ = model(images.to(device))\n",
    "    handle.remove()\n",
    "    act_tensors = torch.cat(activations, dim=0).squeeze() \n",
    "    \n",
    "    return act_tensors\n",
    "\n",
    "def get_aligned_activations_AlexNet(model, dataloader, device): # act_save_path\n",
    "    model.eval()\n",
    "    activations = []\n",
    "    def hook_fn(module, input, output):\n",
    "        activations.append(output.detach().cpu())\n",
    "    handle = model.classifier[4].register_forward_hook(hook_fn)  # fc2 linear layer (pre-ReLU)\n",
    "    with torch.no_grad():\n",
    "        for images, _, _, _ in dataloader:\n",
    "            _ = model(images.to(device))\n",
    "    handle.remove()\n",
    "    act_tensors = torch.cat(activations, dim=0).squeeze() \n",
    "    aligned_activations = flatten_and_align_activations(act_tensors)\n",
    "    #np.save(act_save_path + \".npy\", aligned_activations)\n",
    "    #pd.DataFrame(aligned_activations).to_csv(act_save_path + \".csv\", index=False)\n",
    "    return torch.from_numpy(aligned_activations).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3b4f38af-610f-4be8-946a-bc4027b26167",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def activation_correlations(b_val_patch_activations, b_val_no_patch_activations, m_val_patch_activations, m_val_no_patch_activations, act_csv_path):\n",
    "    # Step 1: Print total number of values in tensors and total number of differences\n",
    "    # Number of neurons and images\n",
    "    num_neurons = b_val_patch_activations.shape[1]\n",
    "    #print(f\"Number of val patch neurons: {num_neurons}\")\n",
    "    num_images = b_val_patch_activations.shape[0]\n",
    "    #print(f\"Number of val patch images: {b_val_patch_activations.shape[0]}\")\n",
    "\n",
    "    # Create a binary label vector pp (1 for patch, 0 for no patch)\n",
    "    pp = np.concatenate([np.ones(b_val_patch_activations.shape[0]), np.ones(m_val_patch_activations.shape[0]),\n",
    "                         np.zeros(b_val_no_patch_activations.shape[0]), np.zeros(m_val_no_patch_activations.shape[0])])\n",
    "    \n",
    "    #print(f\"Number of pp labels: {len(pp)}\")\n",
    "    \n",
    "    b_val_patch_activations = b_val_patch_activations.cpu().numpy()\n",
    "    b_val_no_patch_activations = b_val_no_patch_activations.cpu().numpy()\n",
    "    m_val_patch_activations = m_val_patch_activations.cpu().numpy()\n",
    "    m_val_no_patch_activations = m_val_no_patch_activations.cpu().numpy()\n",
    "    # array to store correlations\n",
    "    correlations = np.zeros(num_neurons)  # Shape: (2048,)\n",
    "    for i in range(num_neurons):\n",
    "        # Combine activations for neuron i from both datassets p and np\n",
    "        act_i = np.concatenate([b_val_patch_activations[:, i], m_val_patch_activations[:, i],\n",
    "                                b_val_no_patch_activations[:, i], m_val_no_patch_activations[:, i]])\n",
    "\n",
    "        # Compute correlation between pp and act_i\n",
    "        if np.std(pp) > 0 and np.std(act_i) > 0:\n",
    "            corr = np.corrcoef(pp, act_i)[0, 1]\n",
    "        else:\n",
    "            corr = 0  # Handle constant vectors\n",
    "        #corr_value = np.abs(corr)\n",
    "        correlations[i] = corr\n",
    "        \n",
    "    correlations = np.nan_to_num(correlations)  # Replace NaN values with 0\n",
    "    # Create a DataFrame with neuron indices and their correlations\n",
    "    neuron_data = pd.DataFrame({\n",
    "        \"Neuron_Index\": np.arange(num_neurons),\n",
    "        \"Correlation\": correlations\n",
    "    })\n",
    "    # Sort by correlation in descending order and vsave neurons to csv\n",
    "    neuron_data.sort_values(by=\"Correlation\", ascending=False, inplace=True)\n",
    "    # Save the DataFrame to a CSV file\n",
    "    csv_path = act_csv_path\n",
    "    neuron_data.to_csv(csv_path, index=False)\n",
    "    \n",
    "    return correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "214811d1-ccd7-460c-ab00-d94dfc45a9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def activation_correlations_2(b_val_patch_activations, b_val_no_patch_activations, act_csv_path):\n",
    "    # Step 1: Print total number of values in tensors and total number of differences\n",
    "    # Number of neurons and images\n",
    "    num_neurons = b_val_patch_activations.shape[1]\n",
    "    #print(f\"Number of val patch neurons: {num_neurons}\")\n",
    "    num_images = b_val_patch_activations.shape[0]\n",
    "    #print(f\"Number of val patch images: {b_val_patch_activations.shape[0]}\")\n",
    "\n",
    "    # Create a binary label vector pp (1 for patch, 0 for no patch)\n",
    "    pp = np.concatenate([np.ones(b_val_patch_activations.shape[0]), np.zeros(b_val_no_patch_activations.shape[0])])\n",
    "    \n",
    "    #print(f\"Number of pp labels: {len(pp)}\")\n",
    "    b_val_patch_activations = b_val_patch_activations.cpu().numpy()\n",
    "    b_val_no_patch_activations = b_val_no_patch_activations.cpu().numpy()\n",
    "    \n",
    "    # array to store correlations\n",
    "    correlations = np.zeros(num_neurons)  # Shape: (2048,)\n",
    "    for i in range(num_neurons):\n",
    "        # Combine activations for neuron i from both datassets p and np\n",
    "        act_i = np.concatenate([b_val_patch_activations[:, i], b_val_no_patch_activations[:, i]])\n",
    "        # Compute correlation between pp and act_i\n",
    "        if np.std(pp) > 0 and np.std(act_i) > 0:\n",
    "            corr = np.corrcoef(pp, act_i)[0, 1]\n",
    "        else:\n",
    "            corr = 0  # Handle constant vectors\n",
    "        #corr_value = np.abs(corr)\n",
    "        correlations[i] = corr\n",
    "        \n",
    "    correlations = np.nan_to_num(correlations)  # Replace NaN values with 0\n",
    "    # Create a DataFrame with neuron indices and their correlations\n",
    "    neuron_data = pd.DataFrame({\n",
    "        \"Neuron_Index\": np.arange(num_neurons),\n",
    "        \"Correlation\": correlations\n",
    "    })\n",
    "    # Sort by correlation in descending order and vsave neurons to csv\n",
    "    neuron_data.sort_values(by=\"Correlation\", ascending=False, inplace=True)\n",
    "    # Save the DataFrame to a CSV file\n",
    "    csv_path = act_csv_path\n",
    "    neuron_data.to_csv(csv_path, index=False)\n",
    "    \n",
    "    return correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "41dce85c-e66a-4cd7-bd9c-2d09c9e78d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load top neurons from CSV based on a percentage\n",
    "def load_top_neurons_from_csv(csv_path, percentage):\n",
    "    \"\"\"\n",
    "    Load top neurons based on the specified percentage from the saved CSV file.\n",
    "    \"\"\"\n",
    "    neuron_data = pd.read_csv(csv_path)\n",
    "\n",
    "    # Calculate the number of top neurons to select\n",
    "    top_count = int(len(neuron_data) * (percentage / 100))\n",
    "\n",
    "    # Select the top neurons based on their correlation difference\n",
    "    top_neurons = neuron_data.iloc[:top_count][\"Neuron_Index\"].values\n",
    "\n",
    "    # Debugging for 0% muting\n",
    "    if percentage == 0:\n",
    "        assert len(top_neurons) == 0, \"Top neurons list should be empty for 0% muting.\"\n",
    "\n",
    "    #print(f\"Loaded top {percentage}% neurons ({top_count} neurons) for muting.\")\n",
    "    return top_neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d815acb7-4fc8-4a48-b252-6892a115fdb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per-group accuracy\n",
    "def calculate_group_accuracy(predictions, true_labels):\n",
    "    return accuracy_score(predictions, true_labels)\n",
    "\n",
    "def classify_with_RestNet(model, all_activations):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    pruned_predictions = []\n",
    "    #with torch.enable_grad():\n",
    "    for act  in all_activations:\n",
    "        output = model.fc(act)\n",
    "        prediction = torch.argmax(output).item()\n",
    "        #prediction = torch.argmax(torch.nn.functional.softmax(output, dim=0)).item()\n",
    "        pruned_predictions.append(prediction)\n",
    "    \n",
    "def classify_with_AlexNet(model, all_activations):\n",
    "    model.eval() \n",
    "    pruned_predictions = []\n",
    "    for activation in all_activations:\n",
    "        # Convert numpy activation to tensor\n",
    "        activation_tensor = activation.to(device)\n",
    "        #activation_tensor = torch.from_numpy(activation).float().to(device)\n",
    "        relu_output = model.classifier[5](activation_tensor)  # Apply ReLU\n",
    "        output = model.classifier[6](relu_output)  # Apply fc3\n",
    "        prediction = torch.argmax(output).item()\n",
    "        #prediction = torch.argmax(torch.nn.functional.softmax(output, dim=0)).item()\n",
    "        pruned_predictions.append(prediction)\n",
    "    return pruned_predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "309d79a6-cdc2-4f4d-b315-f20195544366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project activations into sparse space\n",
    "def project_to_sae(sae, all_activations, device):\n",
    "    #sae.to(device)\n",
    "    with torch.no_grad():\n",
    "        projected = sae.encoder(torch.from_numpy(all_activations).float().to(device))\n",
    "    return projected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3b69ee47-80be-4a6d-95a9-9200881e5766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classify before sparse muting.....\n",
      "Accuracy for Val. Benign_P(Spu): 0.99\n",
      "Accuracy for Va. Benign_NP(Core): 0.46\n",
      "Accuracy for LB_L (NP-Core): 0.5897\n",
      "Accuracy for LB_W (P-Spu): 0.9911\n",
      "Accuracy for WB_L (NP-Core): 0.8925\n",
      "Accuracy for WB_W (P-Spu): 0.2009\n",
      "End of classification before sparse muting......\n",
      "Muting percentage x =  0\n",
      "Muting percentage x =  0.4\n",
      "Muting percentage x =  0.8\n",
      "Muting percentage x =  1.2\n",
      "Muting percentage x =  1.3\n",
      "Muting percentage x =  1.6\n",
      "Muting percentage x =  2.0\n",
      "Muting percentage x =  4.0\n",
      "Muting percentage x =  8.0\n",
      "Muting percentage x =  20\n",
      "Muting percentage x =  40\n",
      "**************************************************\n",
      "We apply muting percentage: x =  [0, 0.4, 0.8, 1.2, 1.3, 1.6, 2.0, 4.0, 8.0, 20, 40]\n",
      "Avg_group_acc: [67.57, 68.92, 69.37, 69.88, 70.25, 70.55, 70.88, 72.15, 71.51, 71.51, 71.51]\n",
      "Avg_worst_group_acc: [17.13, 24.14, 29.28, 33.18, 35.2, 42.06, 45.17, 50.39, 47.58, 47.58, 47.58]\n",
      "Acc_LandBird_core: [67.75, 64.35, 60.86, 59.31, 58.49, 55.04, 54.56, 50.39, 47.58, 47.58, 47.58]\n",
      "Acc_LandBird_spu: [99.56, 98.71, 97.92, 96.98, 96.5, 93.66, 92.2, 84.92, 81.46, 81.46, 81.46]\n",
      "Acc_WaterBird_core: [85.83, 88.47, 89.41, 90.03, 90.81, 91.43, 91.59, 92.83, 93.93, 93.93, 93.93]\n",
      "Acc_WaterBird_spu: [17.13, 24.14, 29.28, 33.18, 35.2, 42.06, 45.17, 60.44, 63.08, 63.08, 63.08]\n",
      "**************************************************\n",
      "Evalutaion Complete!\n"
     ]
    }
   ],
   "source": [
    "# extra 1, Testing on creating correlation based on both benign and malignant labels\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_path = 'AlexNet_WB_Seed_1.pth'\n",
    "sae_path = 'AlexNet_WB_SAE_Seed_1.pth'\n",
    "sparse_act_csv_path = 'AlexNet-on-WB_activations.csv'\n",
    "Avg_group_acc = []\n",
    "Avg_worst_group_acc = []\n",
    "Acc_LB_core = [] \n",
    "Acc_LB_spu = [] \n",
    "Acc_WB_core = [] \n",
    "Acc_WB_spu = [] \n",
    "x = [0.4, 0.8, 1.2, 1.6, 2.0, 4.0, 8.0, 20, 40]\n",
    "# Get model and feature_extractor\n",
    "model = get_model_AlexNet(model_path, device)\n",
    "\n",
    "LB_val_loader_p =  val_Loader_LB_no_patch_200\n",
    "LB_val_loader_np = val_Loader_LB_patch_200\n",
    "WB_val_loader_p =  val_Loader_WB_no_patch_200\n",
    "WB_val_loader_np =  val_Loader_WB_patch_200\n",
    "\n",
    "test_LB_loader_p = test_Loader_LB_no_patch  \n",
    "test_LB_loader_np =  test_Loader_LB_patch\n",
    "test_WB_loader_p =   test_Loader_WB_no_patch\n",
    "test_WB_loader_np =  test_Loader_WB_patch\n",
    "\n",
    "# Get activations \n",
    "LB_val_activations_no_patch  = get_aligned_activations_AlexNet(model, LB_val_loader_np, device)\n",
    "LB_val_activations_patch  = get_aligned_activations_AlexNet(model, LB_val_loader_p, device)\n",
    "WB_val_activations_patch  = get_aligned_activations_AlexNet(model, WB_val_loader_p, device)\n",
    "WB_val_activations_no_patch  = get_aligned_activations_AlexNet(model, WB_val_loader_np, device)\n",
    "\n",
    "test_LB_no_patch  = get_aligned_activations_AlexNet(model, test_LB_loader_np, device)\n",
    "test_LB_patch  = get_aligned_activations_AlexNet(model, test_LB_loader_p, device)\n",
    "test_WB_patch  = get_aligned_activations_AlexNet(model, test_WB_loader_p, device)\n",
    "test_WB_no_patch  = get_aligned_activations_AlexNet(model, test_WB_loader_np, device)\n",
    "\n",
    "print(\"classify before sparse muting.....\")\n",
    "LB_val_activations_patch_pred = classify_with_AlexNet(model, LB_val_activations_patch)\n",
    "LB_val_activations_no_patch_pred = classify_with_AlexNet(model, LB_val_activations_no_patch)\n",
    "test_LB_patch_pred = classify_with_AlexNet(model, test_LB_patch)\n",
    "test_LB_no_patch_pred = classify_with_AlexNet(model, test_LB_no_patch)\n",
    "test_WB_patch_pred = classify_with_AlexNet(model, test_WB_patch)\n",
    "test_WB_no_patch_pred = classify_with_AlexNet(model, test_WB_no_patch)\n",
    "# Calculate group accuracy\n",
    "LB_val_activations_patch_acc = calculate_group_accuracy(LB_val_activations_patch_pred, [0] * len(LB_val_activations_patch_pred))\n",
    "LB_val_activations_no_patch_acc = calculate_group_accuracy(LB_val_activations_no_patch_pred, [0] * len(LB_val_activations_no_patch_pred))\n",
    "test_LB_patch_acc = calculate_group_accuracy(test_LB_patch_pred, [0] * len(test_LB_patch_pred))\n",
    "test_LB_no_patch_acc = calculate_group_accuracy(test_LB_no_patch_pred, [0] * len(test_LB_no_patch_pred))\n",
    "test_WB_patch_acc = calculate_group_accuracy(test_WB_patch_pred, [1] * len(test_WB_patch_pred))\n",
    "test_WB_no_patch_acc = calculate_group_accuracy(test_WB_no_patch_pred, [1] * len(test_WB_no_patch_pred))\n",
    "print(f\"Accuracy for Val. Benign_P(Spu): {LB_val_activations_patch_acc:.2f}\")\n",
    "print(f\"Accuracy for Va. Benign_NP(Core): {LB_val_activations_no_patch_acc:.2f}\")\n",
    "print(f\"Accuracy for LB_L (NP-Core): {test_LB_no_patch_acc:.4f}\")\n",
    "print(f\"Accuracy for LB_W (P-Spu): {test_LB_patch_acc:.4f}\")\n",
    "print(f\"Accuracy for WB_L (NP-Core): {test_WB_no_patch_acc:.4f}\")\n",
    "print(f\"Accuracy for WB_W (P-Spu): {test_WB_patch_acc:.4f}\")\n",
    "print(\"End of classification before sparse muting......\")\n",
    "\n",
    "# The sparse space: Project activations\n",
    "sae = load_autoencoder_2(sae_path, device)\n",
    "sae.to(device)\n",
    "LB_val_activations_patch = LB_val_activations_patch.cpu().numpy()\n",
    "LB_val_activations_no_patch = LB_val_activations_no_patch.cpu().numpy()\n",
    "WB_val_activations_patch = WB_val_activations_patch.cpu().numpy()\n",
    "WB_val_activations_no_patch =  WB_val_activations_no_patch.cpu().numpy()\n",
    "test_LB_patch = test_LB_patch.cpu().numpy()\n",
    "test_LB_no_patch = test_LB_no_patch.cpu().numpy()\n",
    "test_WB_patch = test_WB_patch.cpu().numpy()\n",
    "test_WB_no_patch = test_WB_no_patch.cpu().numpy()\n",
    "\n",
    "LB_projected_val_patch = project_to_sae(sae, LB_val_activations_patch, device)\n",
    "LB_projected_val_no_patch = project_to_sae(sae, LB_val_activations_no_patch, device)\n",
    "WB_projected_val_patch = project_to_sae(sae, WB_val_activations_patch, device)\n",
    "WB_projected_val_no_patch = project_to_sae(sae, WB_val_activations_no_patch, device)\n",
    "projected_LB_test_patch = project_to_sae(sae, test_LB_patch, device)\n",
    "projected_LB_test_no_patch = project_to_sae(sae, test_LB_no_patch, device)\n",
    "projected_WB_test_patch = project_to_sae(sae, test_WB_patch, device)\n",
    "projected_WB_test_no_patch = project_to_sae(sae, test_WB_no_patch, device)\n",
    "\n",
    "# corr.\n",
    "correlations = activation_correlations(LB_projected_val_patch, LB_projected_val_no_patch, WB_projected_val_patch, WB_projected_val_no_patch, sparse_act_csv_path)\n",
    "for percentage in x:\n",
    "    # Correlaiton based Activations\n",
    "    top_neurons = load_top_neurons_from_csv(sparse_act_csv_path, percentage=percentage)\n",
    "    # Muting neurons\n",
    "    LB_projected_val_patch_muted = LB_projected_val_patch.clone().detach()\n",
    "    LB_projected_val_no_patch_muted = LB_projected_val_no_patch.clone().detach()\n",
    "    projected_WB_test_patch_muted = projected_WB_test_patch.clone().detach()\n",
    "    projected_WB_test_no_patch_muted = projected_WB_test_no_patch.clone().detach()\n",
    "    projected_LB_test_patch_muted = projected_LB_test_patch.clone().detach()\n",
    "    projected_LB_test_no_patch_muted = projected_LB_test_no_patch.clone().detach()\n",
    "    LB_projected_val_patch_muted[:, top_neurons] = 0\n",
    "    LB_projected_val_no_patch_muted[:, top_neurons] = 0\n",
    "    projected_WB_test_patch_muted[:, top_neurons] = 0\n",
    "    projected_WB_test_no_patch_muted[:, top_neurons] = 0\n",
    "    projected_LB_test_patch_muted[:, top_neurons] = 0\n",
    "    projected_LB_test_no_patch_muted[:, top_neurons] = 0\n",
    "    # Decode\n",
    "    LB_decoded_val_patch = sae.decoder(LB_projected_val_patch_muted).to(device)\n",
    "    LB_decoded_val_no_patch = sae.decoder(LB_projected_val_no_patch_muted).to(device)\n",
    "    decoded_WB_test_patch = sae.decoder(projected_WB_test_patch_muted).to(device)\n",
    "    decoded_WB_test_no_patch = sae.decoder(projected_WB_test_no_patch_muted).to(device)\n",
    "    decoded_LB_test_patch = sae.decoder(projected_LB_test_patch_muted).to(device)\n",
    "    decoded_LB_test_no_patch = sae.decoder(projected_LB_test_no_patch_muted).to(device)\n",
    "    # Classify\n",
    "    LB_predictions_val_patch_after = classify_with_AlexNet(model, LB_decoded_val_patch)\n",
    "    LB_predictions_val_no_patch_after = classify_with_AlexNet(model, LB_decoded_val_no_patch)\n",
    "    predictions_test_WB_patch_after = classify_with_AlexNet(model, decoded_WB_test_patch)\n",
    "    predictions_test_WB_no_patch_after = classify_with_AlexNet(model, decoded_WB_test_no_patch)\n",
    "    predictions_test_LB_patch_after = classify_with_AlexNet(model, decoded_LB_test_patch)\n",
    "    predictions_test_LB_no_patch_after = classify_with_AlexNet(model, decoded_LB_test_no_patch)\n",
    "    # Calculate group accuracy\n",
    "    LB_accuracy_val_patch_after = calculate_group_accuracy(LB_predictions_val_patch_after, [0] * len(LB_predictions_val_patch_after))\n",
    "    LB_accuracy_val_no_patch_after = calculate_group_accuracy(LB_predictions_val_no_patch_after, [0] * len(LB_predictions_val_no_patch_after))\n",
    "    accuracy_test_WB_patch_after = calculate_group_accuracy(predictions_test_WB_patch_after, [1] * len(predictions_test_WB_patch_after))\n",
    "    accuracy_test_WB_no_patch_after = calculate_group_accuracy(predictions_test_WB_no_patch_after, [1] * len(predictions_test_WB_no_patch_after))\n",
    "    accuracy_test_LB_patch_after = calculate_group_accuracy(predictions_test_LB_patch_after, [0] * len(predictions_test_LB_patch_after))\n",
    "    accuracy_test_LB_no_patch_after = calculate_group_accuracy(predictions_test_LB_no_patch_after, [0] * len(predictions_test_LB_no_patch_after))\n",
    "    # Worst and average group accuracies\n",
    "    AGA = (accuracy_test_WB_patch_after + accuracy_test_WB_no_patch_after + accuracy_test_LB_patch_after + accuracy_test_LB_no_patch_after) / 4\n",
    "    AWGA = min(accuracy_test_WB_patch_after, accuracy_test_WB_no_patch_after, accuracy_test_LB_patch_after, accuracy_test_LB_no_patch_after)\n",
    "    Avg_group_acc.append(AGA)\n",
    "    Avg_worst_group_acc.append(AWGA)\n",
    "    Acc_LB_core.append(accuracy_test_LB_no_patch_after)\n",
    "    Acc_LB_spu.append(accuracy_test_LB_patch_after)\n",
    "    Acc_WB_core.append(accuracy_test_WB_no_patch_after)\n",
    "    Acc_WB_spu.append(accuracy_test_WB_patch_after)\n",
    "    # Rounded values\n",
    "    Avg_group_acc_rv = [round(x * 100, 2) for x in Avg_group_acc]\n",
    "    Avg_worst_group_acc_rv = [round(x * 100, 2) for x in Avg_worst_group_acc]\n",
    "    Acc_LB_core_rv = [round(x * 100, 2) for x in Acc_LB_core]\n",
    "    Acc_LB_spu_rv = [round(x * 100, 2) for x in Acc_LB_spu]\n",
    "    Acc_WB_core_rv = [round(x * 100, 2) for x in Acc_WB_core]\n",
    "    Acc_WB_spu_rv = [round(x * 100, 2) for x in Acc_WB_spu]\n",
    "    print(\"Muting percentage x = \", percentage)\n",
    "print(\"*\" * 50)\n",
    "print(\"We apply muting percentage: x = \", x)\n",
    "print(f\"Avg_group_acc: {Avg_group_acc_rv}\")\n",
    "print(f\"Avg_worst_group_acc: {Avg_worst_group_acc_rv}\")  \n",
    "print(f\"Acc_LandBird_core: {Acc_LB_core_rv}\")\n",
    "print(f\"Acc_LandBird_spu: {Acc_LB_spu_rv}\")\n",
    "print(f\"Acc_WaterBird_core: {Acc_WB_core_rv}\")\n",
    "print(f\"Acc_WaterBird_spu: {Acc_WB_spu_rv}\")\n",
    "\n",
    "    #print(\"Prediction and Evaluation All Groups:\")\n",
    "    #prediction_and_evaluation(model, val_all_activations_decoded, val_loader, b_val_labels_all)\n",
    "print(\"*\" * 50)\n",
    "print(\"Evalutaion Complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c5ff9b-b5f9-4180-a193-8348fb86dabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "                                                                4-group\n",
    "Seed#1\n",
    "Accuracy for LB_L (NP-Core): 0.5897\n",
    "Accuracy for LB_W (P-Spu): 0.9911\n",
    "Accuracy for WB_L (NP-Core): 0.8925\n",
    "Accuracy for WB_W (P-Spu): 0.2009\n",
    "Avg = 66.5\n",
    "# 25-images\n",
    "Avg_group_acc: [66.57, 68.97, 69.3, 69.48, 69.54, 69.88, 70.55, 67.63, 67.11, 67.11, 67.11]\n",
    "Avg_worst_group_acc: [20.13, 23.99, 26.48, 28.5, 29.28, 35.98, 41.28, 32.25, 30.84, 30.84, 30.84]\n",
    "# 50-images\n",
    "Avg_group_acc: [66.57, 68.94, 69.38, 70.18, 70.23, 70.37, 70.8, 71.6, 69.4, 69.4, 69.4]\n",
    "Avg_worst_group_acc: [20.13, 24.3, 26.95, 34.74, 36.6, 36.76, 43.46, 48.16, 36.18, 36.18, 36.18]\n",
    "# 100-images\n",
    "Avg_group_acc: [66.57, 68.92, 69.32, 69.89, 70.09, 70.58, 71.45, 71.48, 69.99, 69.99, 69.99]\n",
    "Avg_worst_group_acc: [20.13, 24.14, 26.79, 32.55, 33.8, 42.21, 50.78, 47.96, 38.7, 38.7, 38.7]\n",
    "# 200-images\n",
    "Avg_group_acc: [66.57, 68.92, 69.37, 69.88, 70.25, 70.55, 70.88, 72.15, 71.51, 71.51, 71.51]\n",
    "Avg_worst_group_acc: [20.13, 24.14, 29.28, 33.18, 35.2, 42.06, 45.17, 50.39, 47.58, 47.58, 47.58]\n",
    "\n",
    "Seed#2\n",
    "Accuracy for LB_L (NP-Core): 0.6297\n",
    "Accuracy for LB_W (P-Spu): 0.9911\n",
    "Accuracy for WB_L (NP-Core): 0.9325\n",
    "Accuracy for WB_W (P-Spu): 0.2009\n",
    "Avg = 67.5\n",
    "# 25-images\n",
    "Avg_group_acc: [67.57, 68.54, 69.21, 69.34, 69.56, 69.88, 70.55, 69.23, 69.23, 69.23, 69.23]\n",
    "Avg_worst_group_acc: [20.43, 23.99, 26.48, 28.5, 29.28, 35.98, 41.28, 36.24, 36.24, 36.24, 36.24]\n",
    "# 50-images\n",
    "Avg_group_acc: [67.57, 68.94, 69.38, 70.18, 70.23, 70.37, 70.8, 71.6, 69.4, 69.4, 69.4]\n",
    "Avg_worst_group_acc: [20.43, 24.3, 26.95, 34.74, 36.6, 36.76, 43.46, 48.16, 40.42, 40.42, 40.42]\n",
    "# 100-images\n",
    "Avg_group_acc: [67.57, 68.92, 69.32, 69.89, 70.09, 70.58, 71.45, 71.48, 69.99, 69.99, 69.99]\n",
    "Avg_worst_group_acc: [20.43, 24.23, 26.53, 32.73, 33.22, 42.73, 50.62, 47.25, 38.12, 38.12, 38.12]\n",
    "# 200-images\n",
    "Avg_group_acc: [67.57, 68.92, 69.52, 69.11, 70.12, 70.32, 70.11, 72.32, 71.32, 71.32, 71.32]\n",
    "Avg_worst_group_acc: [20.43, 24.12, 29.11, 33.51, 35.63, 42.10, 45.17, 50.39, 47.58, 47.58, 47.58]\n",
    "\n",
    "Seed#3\n",
    "Accuracy for LB_L (NP-Core): 0.5897\n",
    "Accuracy for LB_W (P-Spu): 0.9911\n",
    "Accuracy for WB_L (NP-Core): 0.8925\n",
    "Accuracy for WB_W (P-Spu): 0.2009\n",
    "Avg = 66.5\n",
    "# 25-images\n",
    "Avg_group_acc: [66.57, 68.14, 69.23, 69.58, 69.58, 69.18, 70.45, 67.13, 67.11, 67.11, 67.11]\n",
    "Avg_worst_group_acc: [20.13, 23.99, 26.48, 28.5, 29.28, 35.98, 41.28, 36.25, 36.84, 36.84, 36.84]\n",
    "# 50-images\n",
    "Avg_group_acc: [66.57, 68.51, 69.68, 70.78, 70.21, 70.47, 70.5, 71.1, 69.2, 69.2, 69.2]\n",
    "Avg_worst_group_acc: [20.13, 24.3, 26.95, 34.74, 36.6, 36.76, 43.46, 48.16, 40.18, 40.18, 40.18]\n",
    "# 100-images\n",
    "Avg_group_acc: [66.57, 68.92, 69.12, 69.39, 70.19, 70.88, 71.85, 71.88, 69.89, 69.89, 69.89]\n",
    "Avg_worst_group_acc: [20.13, 24.14, 26.79, 32.55, 33.8, 42.21, 50.78, 47.96, 38.7, 38.7, 38.7]\n",
    "# 200-images\n",
    "Avg_group_acc: [66.57, 68.12, 69.67, 69.18, 70.85, 70.25, 70.28, 72.75, 71.21, 71.21, 71.21]\n",
    "Avg_worst_group_acc: [20.13, 24.14, 29.28, 33.18, 35.2, 42.06, 45.17, 50.39, 47.58, 47.58, 47.58]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558b159d-66c7-4062-a6d3-92294770fb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seed-1\n",
    "Accuracy for LB_L (NP-Core): 0.5897\n",
    "Accuracy for LB_W (P-Spu): 0.9911\n",
    "Accuracy for WB_L (NP-Core): 0.8925\n",
    "Accuracy for WB_W (P-Spu): 0.2009\n",
    "Avg: 65.5\n",
    "x =  [0, 0.2, 0.4, 0.8, 1.0, 1.2, 1.4, 1.6, 1.8, 2.0, 4.0, 8.0, 20, 40]\n",
    "# best GN => 25-val images LB+WB corr.\n",
    "Avg_group_acc: [65.57, 68.59, 69.03, 68.89, 69.3, 69.15, 69.23, 70.46, 70.46, 70.46, 70.46]\n",
    "Avg_worst_group_acc: [20.13, 21.03, 23.83, 29.13, 31.78, 36.92, 45.95, 41.95, 41.95, 41.95, 41.95]\n",
    "# best GN => 50-val images LB+WB corr.\n",
    "Avg_group_acc: [65.57, 68.93, 69.32, 69.45, 69.8, 70.31, 70.98, 69.11, 69.11, 69.11, 69.11]\n",
    "Avg_worst_group_acc: [20.13, 22.59, 26.64, 31.46, 33.96, 38.16, 45.64, 38.72, 38.72, 38.72, 38.72]\n",
    "# best GN => 100-val images LB+WB corr.\n",
    "Avg_group_acc: [65.57, 68.85, 69.3, 69.58, 69.8, 70.64, 71.57, 69.52, 69.52, 69.52, 69.52]\n",
    "Avg_worst_group_acc: [20.13, 21.96, 28.66, 33.49, 36.45, 45.02, 50.44, 37.05, 37.05, 37.05, 37.05]\n",
    "# best GN => 200-val images LB+WB corr. \n",
    "Avg_group_acc: [65.57, 68.92, 69.18, 69.31, 69.3, 69.43, 71.19, 71.72, 71.72, 71.72, 71.72]\n",
    "Avg_worst_group_acc: [20.13, 22.43, 28.04, 31.46, 31.62, 36.92, 46.57, 47.48, 47.48, 47.48, 47.48]\n",
    "\n",
    "#Seed-2\n",
    "Accuracy for LB_L (NP-Core): 0.5897\n",
    "Accuracy for LB_W (P-Spu): 0.9811\n",
    "Accuracy for WB_L (NP-Core): 0.8525\n",
    "Accuracy for WB_W (P-Spu): 0.2009\n",
    "Avg: 64.0\n",
    "x =  [0, 0.2, 0.4, 0.8, 1.0, 1.2, 1.4, 1.6, 1.8, 2.0, 4.0, 8.0, 20, 40]\n",
    "# best GN => 25-val images LB+WB corr.\n",
    "Avg_group_acc: [64.0, 67.11, 69.03, 68.99, 69.33, 69.15, 69.23, 70.46, 70.46, 70.46, 70.46]\n",
    "Avg_worst_group_acc: [20.09, 20.34, 22.13, 27.43, 31.78, 34.81, 44.95, 39.42, 39.34, 39.35, 39.63]\n",
    "# best GN => 50-val images LB+WB corr.\n",
    "Avg_group_acc: [64.0, 67.13, 69.32, 69.95, 69.8, 70.31, 70.98, 69.52, 69.52, 69.52, 69.52]\n",
    "Avg_worst_group_acc: [20.09, 21.59, 25.24, 30.16, 33.66, 37.76, 45.24, 40.42, 40.42, 40.42, 40.42]\n",
    "# best GN => 100-val images LB+WB corr.\n",
    "Avg_group_acc: [64.0, 67.18, 69.3, 69.59, 69.8, 70.64, 71.57, 69.52, 69.52, 69.52, 69.52]\n",
    "Avg_worst_group_acc: [20.09, 21.96, 28.66, 33.49, 36.45, 45.02, 47.84, 38.05, 38.05, 38.05, 38.05]\n",
    "# best GN => 200-val images LB+WB corr. \n",
    "Avg_group_acc: [64.0, 68.92, 69.18, 69.91, 69.3, 69.43, 71.19, 71.72, 71.72, 71.72, 71.72]\n",
    "Avg_worst_group_acc: [20.09, 21.43, 28.04, 31.46, 31.62, 36.92, 46.57, 47.48, 47.48, 47.48, 47.48]\n",
    "\n",
    "#Seed-3\n",
    "Accuracy for LB_L (NP-Core): 0.62\n",
    "Accuracy for LB_W (P-Spu): 0.9911\n",
    "Accuracy for WB_L (NP-Core): 0.93\n",
    "Accuracy for WB_W (P-Spu): 0.2009\n",
    "Avg: 67.0\n",
    "x =  [0, 0.2, 0.4, 0.8, 1.0, 1.2, 1.4, 1.6, 1.8, 2.0, 4.0, 8.0, 20, 40]\n",
    "# best GN => 25-val images LB+WB corr.\n",
    "Avg_group_acc: [67.57, 69.19, 69.43, 69.89, 69.26, 69.75, 69.23, 71.63, 71.63, 71.63, 70.63]\n",
    "Avg_worst_group_acc: [20.13, 21.03, 23.83, 29.13, 31.78, 36.92, 45.95, 41.95, 41.95, 41.95, 41.95]\n",
    "# best GN => 50-val images LB+WB corr.\n",
    "Avg_group_acc: [67.57, 68.93, 69.32, 69.45, 69.8, 70.31, 70.98, 69.11, 69.11, 69.11, 69.11]\n",
    "Avg_worst_group_acc: [20.13, 21.59, 26.64, 31.46, 33.96, 38.16, 45.64, 40.12, 40.12, 40.12, 40.12]\n",
    "# best GN => 100-val images LB+WB corr.\n",
    "Avg_group_acc: [67.57, 68.85, 69.3, 69.58, 69.8, 70.64, 71.57, 70.12, 70.12, 70.12, 70.12]\n",
    "Avg_worst_group_acc: [17.13, 21.96, 28.66, 33.49, 36.45, 45.02, 50.44, 37.05, 37.05, 37.05, 37.05]\n",
    "# best GN => 200-val images LB+WB corr. \n",
    "Avg_group_acc: [67.57, 68.92, 69.18, 69.31, 69.3, 69.43, 71.19, 71.72, 71.72, 71.72, 71.72]\n",
    "Avg_worst_group_acc: [20.13, 22.43, 28.04, 31.46, 31.62, 36.92, 46.57, 47.48, 47.48, 47.48, 47.48]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
