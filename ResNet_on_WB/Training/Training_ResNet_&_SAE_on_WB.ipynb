{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model::\n",
      "Size of WB_train_loader :  4864\n",
      "Epoch [1/200] Train Loss: 0.1534, Val Loss: 0.4413, Train Acc: 0.9347, Val Acc: 0.8180\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at inline_container.cc:595] . unexpected pos 2760192 vs 2760088",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py:628\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _open_zipfile_writer(f) \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[0;32m--> 628\u001b[0m     \u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_protocol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_disable_byteorder_record\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py:862\u001b[0m, in \u001b[0;36m_save\u001b[0;34m(obj, zip_file, pickle_module, pickle_protocol, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    861\u001b[0m num_bytes \u001b[38;5;241m=\u001b[39m storage\u001b[38;5;241m.\u001b[39mnbytes()\n\u001b[0;32m--> 862\u001b[0m \u001b[43mzip_file\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_record\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_ptr\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at inline_container.cc:764] . PytorchStreamWriter failed writing file data/144: file write failed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 201\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining Model::\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSize of WB_train_loader : \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(WB_train_loader)\u001b[38;5;241m*\u001b[39mbatch_size)\n\u001b[0;32m--> 201\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mWB_train_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mWB_val_loader_WB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresnet_writer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining complete:: \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    203\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(model\u001b[38;5;241m.\u001b[39mstate_dict(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mResNet_WB.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[12], line 196\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, val_loader, criterion, optimizer, writer, num_epochs)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m val_acc \u001b[38;5;241m>\u001b[39m best_val_acc:\n\u001b[1;32m    195\u001b[0m     best_val_acc \u001b[38;5;241m=\u001b[39m val_acc\n\u001b[0;32m--> 196\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mResNet_WB_best.pth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest model saved at epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with Val Acc: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py:627\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    624\u001b[0m _check_save_filelike(f)\n\u001b[1;32m    626\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[0;32m--> 627\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _open_zipfile_writer(f) \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[1;32m    628\u001b[0m         _save(obj, opened_zipfile, pickle_module, pickle_protocol, _disable_byteorder_record)\n\u001b[1;32m    629\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py:475\u001b[0m, in \u001b[0;36m_open_zipfile_writer_file.__exit__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 475\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfile_like\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_end_of_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    476\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_stream \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    477\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_stream\u001b[38;5;241m.\u001b[39mclose()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at inline_container.cc:595] . unexpected pos 2760192 vs 2760088"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, transforms, datasets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import *\n",
    "import PIL.Image\n",
    "from torch.utils.data import DataLoader, DistributedSampler\n",
    "from torchvision.models import AlexNet_Weights, resnet50, ResNet50_Weights, resnet18, ResNet18_Weights, resnet101, ResNet101_Weights, VGG19_Weights, vgg19\n",
    "import torch.distributed as dist\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from sklearn.decomposition import PCA\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "# Best settings for most CNN training\n",
    "torch.backends.cudnn.benchmark = True     \n",
    "torch.backends.cudnn.deterministic = False  \n",
    "torch.backends.cudnn.enabled = True \n",
    "\n",
    "resnet_writer = SummaryWriter(log_dir='ResNet-50-full-model/resnet_WB')\n",
    "sae_writer = SummaryWriter(log_dir='ResNet-50-full-model/sae_WB')\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.manual_seed(1111)\n",
    "np.random.seed(1111)\n",
    "\n",
    "class SparseAutoEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, sparsity_lambda=0.70, xavier_norm_init=True):\n",
    "        super(SparseAutoEncoder, self).__init__()\n",
    "        self.sparsity_lambda = sparsity_lambda\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.GroupNorm(num_groups=16, num_channels=hidden_dim),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        if xavier_norm_init:\n",
    "            nn.init.xavier_uniform_(self.encoder[0].weight)  # Xavier initialization\n",
    "            \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, input_dim),\n",
    "            #nn.ReLU() #nn.Sigmoid()  # Output between 0-1\n",
    "        )\n",
    "        if xavier_norm_init:\n",
    "            nn.init.xavier_uniform_(self.decoder[0].weight)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return encoded, decoded\n",
    "    \n",
    "    def kl_sparsity_penalty(self, encoded):\n",
    "        # Penalize the average absolute activation\n",
    "        rho_hat = torch.mean(torch.abs(encoded), dim=0)  # Average absolute activation per hidden unit\n",
    "        rho = torch.ones_like(rho_hat) * self.sparsity_target  # Target sparsity value\n",
    "        epsilon = 1e-8  # Small value to avoid log(0)\n",
    "        \n",
    "        # KL-divergence computation for sparsity\n",
    "        kl_divergence = rho * torch.log(rho / (rho_hat + epsilon)) + (1 - rho) * torch.log((1 - rho) / (1 - rho_hat + epsilon))\n",
    "        kl_divergence = torch.sum(kl_divergence)  # Sum over all hidden units\n",
    "\n",
    "        return self.sparsity_lambda * kl_divergence\n",
    "\n",
    "    # L1-norm sparsity penalty calculation\n",
    "    def l1_sparsity_penalty(self, encoded):\n",
    "        # Compute the mean of absolute values of activations\n",
    "        sparsity_loss = torch.mean(torch.abs(encoded))  # Average absolute activation across all units\n",
    "        return self.sparsity_lambda * sparsity_loss  # Scale by the sparsity weight\n",
    "    \n",
    "    def kl_divergence(self, rho_hat, rho=0.05): # added\n",
    "        rho_hat = torch.clamp(rho_hat, 1e-8, 1-1e-8)\n",
    "        return torch.sum(rho * torch.log(rho / rho_hat) + (1-rho)*torch.log((1-rho)/(1-rho_hat)))\n",
    "\n",
    "    # Loss function combining MSE (reconstruction error) and sparsity penalty\n",
    "    def loss_function(self, decoded, original, encoded):\n",
    "        mse_loss = F.mse_loss(decoded, original)  # Mean Squared Error for reconstruction\n",
    "        sparsity_loss = self.l1_sparsity_penalty(encoded)  # Sparsity penalty for hidden layer activations\n",
    "        return mse_loss + sparsity_loss  # Total loss is MSE + sparsity penalty\n",
    "\n",
    "# 1. Define Dataset with Metadata\n",
    "class WaterbirdsDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        self.metadata = pd.read_csv(csv_file)  # Metadata file with bird type and background\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.metadata)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = f\"{self.root_dir}/{self.metadata.iloc[idx]['img_filename']}\"\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        bird_type = self.metadata.iloc[idx]['y']  # Waterbird=1, Landbird=0\n",
    "        background = self.metadata.iloc[idx]['place']  # Water=1, Land=0\n",
    "        label = bird_type  # For training, we only care about bird type\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label, bird_type, background\n",
    "        \n",
    "# 2. Transforms and Data Preparation\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load training and testing datasets for WaterBirds_Dataset\n",
    "WB_train_dataset = WaterbirdsDataset(\n",
    "    csv_file = '/run/determined/workdir/SCLearning_WB/split-metadata/output_metadata/train_metadata_updated.csv',\n",
    "    #csv_file = '/home/ahsan/test-project/fss/split-metadata/output_metadata/train_metadata_updated_samples.csv',\n",
    "    root_dir= '/run/determined/workdir/SCLearning_WB/WB_DB/all_images_DB/train_DB/all_birds_train',\n",
    "    transform=transform\n",
    ")\n",
    "WB_test_dataset = WaterbirdsDataset(\n",
    "    csv_file='/run/determined/workdir/SCLearning_WB/split-metadata/output_metadata/test_metadata_updated.csv',\n",
    "    #csv_file='/home/ahsan/test-project/fss/split-metadata/output_metadata/test_metadata_updated_samples.csv',\n",
    "    root_dir='/run/determined/workdir/SCLearning_WB/WB_DB/all_images_DB/test_DB/all_birds_test',\n",
    "    transform=transform\n",
    ")\n",
    "WB_val_dataset_WB = WaterbirdsDataset(\n",
    "    csv_file='/run/determined/workdir/SCLearning_WB/split-metadata/output_metadata/val_metadata_WB+LB.csv',\n",
    "    root_dir='/run/determined/workdir/SCLearning_WB/WB_DB/all_images_DB',\n",
    "    transform=transform\n",
    ")\n",
    "batch_size = 128\n",
    "WB_train_loader = DataLoader(WB_train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "WB_test_loader = DataLoader(WB_test_dataset, batch_size=1, shuffle=False, num_workers=4, pin_memory=True)\n",
    "WB_val_loader_WB = DataLoader(WB_val_dataset_WB, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "# 3. Define the ResNet Model for Binary Classification\n",
    "num_classes = 2\n",
    "model = models.resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)  # Output for 2 classes\n",
    "model = model.to(device)\n",
    "# 4. Loss and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-3)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.05, momentum=0.9, weight_decay=1e-4, nesterov=True)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=2)\n",
    "\n",
    "# 5. Training Loop\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, writer, num_epochs):\n",
    "    best_val_acc = 0.0\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss, correct, total = 0, 0, 0\n",
    "        for images, labels, _, _ in train_loader:\n",
    "            images, labels = images.to(device=device), labels.to(device=device)\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            # Apply gradient clipping\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=2.0)\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            correct += (outputs.argmax(1) == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "        \n",
    "        train_loss = total_loss / len(train_loader)\n",
    "        train_acc = correct / total\n",
    "        # Validation... \n",
    "        model.eval()\n",
    "        val_loss, val_correct, val_total = 0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels, _, _ in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                val_correct += (outputs.argmax(1) == labels).sum().item()\n",
    "                val_total += labels.size(0)\n",
    "        val_loss /= len(val_loader)\n",
    "        val_acc = val_correct / val_total\n",
    "        #scheduler.step(val_loss)\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "        writer.add_scalar(\"Loss/train\", train_loss, epoch)\n",
    "        writer.add_scalar(\"Loss/val\", val_loss, epoch)\n",
    "        writer.add_scalar(\"Accuracy/train\", train_acc, epoch)\n",
    "        writer.add_scalar(\"Accuracy/val\", val_acc, epoch)\n",
    "        # Save the best model\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), 'ResNet_WB_best.pth')\n",
    "            print(f\"Best model saved at epoch {epoch+1} with Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "print(\"Training Model::\")\n",
    "print(\"Size of WB_train_loader : \", len(WB_train_loader)*batch_size)\n",
    "train_model(model, WB_train_loader, WB_val_loader_WB, criterion, optimizer, resnet_writer, num_epochs=200)\n",
    "print(\"Training complete:: \")\n",
    "torch.save(model.state_dict(), 'ResNet_WB.pth')\n",
    "# 6. Testing for Four Classes\n",
    "def test_model(model, dataloader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model_predictions = []\n",
    "    #with torch.enable_grad():\n",
    "    for images, lables, bird_type, background  in dataloader:\n",
    "        images = images.to(device)\n",
    "        output = model(images)\n",
    "        prediction = torch.argmax(torch.nn.functional.softmax(output, dim=1)).item() # predictions = torch.argmax(outputs, dim=1) \n",
    "        model_predictions.append(prediction)\n",
    "    \n",
    "    print(\"Results:\", \"*\" * 50)\n",
    "    results = {\"Landbird_Land\": 0, \"Landbird_Water\": 0, \"Waterbird_Land\": 0, \"Waterbird_Water\": 0}\n",
    "    counts = {\"Landbird_Land\": 0, \"Landbird_Water\": 0, \"Waterbird_Land\": 0, \"Waterbird_Water\": 0}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for (images, labels, bird_type, background), pred in zip(dataloader, model_predictions):\n",
    "            if bird_type.item() == 0 and background.item() == 0:\n",
    "                results[\"Landbird_Land\"] += (pred == 0)\n",
    "                counts[\"Landbird_Land\"] += 1\n",
    "            elif bird_type.item() == 0 and background.item() == 1:\n",
    "                results[\"Landbird_Water\"] += (pred == 0)\n",
    "                counts[\"Landbird_Water\"] += 1\n",
    "            elif bird_type.item() == 1 and background.item() == 0:\n",
    "                results[\"Waterbird_Land\"] += (pred == 1)\n",
    "                counts[\"Waterbird_Land\"] += 1\n",
    "            elif bird_type.item() == 1 and background.item() == 1:\n",
    "                results[\"Waterbird_Water\"] += (pred == 1)\n",
    "                counts[\"Waterbird_Water\"] += 1\n",
    "\n",
    "        # Calculate accuracies for each group\n",
    "        for key in results:\n",
    "            if counts[key] > 0:\n",
    "                print(f\"Accuracy for {key}: {results[key] / counts[key]:.2f}\")\n",
    "            else:\n",
    "                print(f\"No samples for {key}\")\n",
    "                \n",
    "# Example usage\n",
    "print(\"Testing Model::\")\n",
    "print(\"size of WB_test_loader : \", len(WB_test_loader))\n",
    "test_model(model, WB_test_loader, device=device)\n",
    "\n",
    "def save_activations(model, dataloader, save_path):\n",
    "    model.eval()\n",
    "    activations = []\n",
    "    def hook_fn(module, input, output):\n",
    "        activations.append(output.detach().cpu())\n",
    "    handle = model.avgpool.register_forward_hook(hook_fn)\n",
    "    with torch.no_grad():\n",
    "        for images, _, _, _ in dataloader:\n",
    "            model(images.to(device))\n",
    "    handle.remove()    \n",
    "    act_tensor = torch.cat(activations, dim=0).squeeze()  # shape: (N, 2048)\n",
    "    np.save(save_path + \".npy\", act_tensor.numpy())\n",
    "    pd.DataFrame(act_tensor.numpy()).to_csv(save_path + \".csv\", index=False)\n",
    "\n",
    "# Load best model\n",
    "model = models.resnet50(weights=None)\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes) \n",
    "model.load_state_dict(torch.load(\"ResNet_WB.pth\", map_location=device))\n",
    "model.eval()\n",
    "model.to(device)\n",
    "# Save activations for test set\n",
    "save_activations(model, WB_train_loader, \"ResNet_WB_act\")\n",
    "print(\"WB_train_activations save successfully!\")\n",
    "# SAE Train Loop\n",
    "def train_sae(model, data, epochs, lr, batch_size, writer):\n",
    "    model.train()\n",
    "    model.to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-3)\n",
    "\n",
    "    dataloader = DataLoader(data, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0\n",
    "        for batch in dataloader:\n",
    "            #batch = torch.stack(batch).to(device)\n",
    "            batch = batch[0].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            encoded, decoded = model(batch)\n",
    "            loss = model.loss_function(decoded, batch, encoded)\n",
    "            #loss = criterion(decoded, batch) + sparsity_loss(encoded, sparsity_lambda)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=2.0)\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "        avg_loss = epoch_loss / len(dataloader)\n",
    "        sae_writer.add_scalar(\"Loss/train\", avg_loss, epoch)\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], SAE Loss: {avg_loss:.4f}\")\n",
    "        \n",
    "# Load previously saved activations\n",
    "activations_np = np.load(\"ResNet_WB_act.npy\")\n",
    "activations = torch.tensor(activations_np, dtype=torch.float32)\n",
    "# Wrap into a TensorDataset\n",
    "activation_dataset = TensorDataset(activations)\n",
    "# Define model\n",
    "sae = SparseAutoEncoder(input_dim=2048, hidden_dim=8000)\n",
    "train_sae(sae, activation_dataset, epochs=300, lr=0.001, batch_size=32, writer=sae_writer)\n",
    "torch.save(sae.state_dict(), 'ResNet_WB_SAE.pth')\n",
    "print(\"Training SAE complete!!\")\n",
    "resnet_writer.close()\n",
    "sae_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
